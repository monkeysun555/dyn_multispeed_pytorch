player initial finish
Episode starts from:  1
episode: 500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-500.pth
Episode: 500 Reward: -463.496 Loss: 12.185
episode: 1000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-1000.pth
Episode: 1000 Reward: -516.652 Loss: 54.355
episode: 1500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-1500.pth
Episode: 1500 Reward: -561.524 Loss: 66.105
episode: 2000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-2000.pth
Episode: 2000 Reward: -1327.754 Loss: 18.688
episode: 2500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-2500.pth
Episode: 2500 Reward: -513.480 Loss: 102.391
episode: 3000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-3000.pth
Episode: 3000 Reward: -436.645 Loss: 67.126
episode: 3500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-3500.pth
Episode: 3500 Reward: -513.290 Loss: 56.877
episode: 4000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-4000.pth
Episode: 4000 Reward: -508.902 Loss: 22.027
episode: 4500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-4500.pth
Episode: 4500 Reward: -523.002 Loss: 75.962
episode: 5000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-5000.pth
Episode: 5000 Reward: -750.753 Loss: 49.101
episode: 5500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-5500.pth
Episode: 5500 Reward: -348.767 Loss: 60.540
episode: 6000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-6000.pth
Episode: 6000 Reward: -2094.616 Loss: 79.520
episode: 6500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-6500.pth
Episode: 6500 Reward: -315.949 Loss: 50.716
episode: 7000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-7000.pth
Episode: 7000 Reward: -319.817 Loss: 68.120
episode: 7500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-7500.pth
Episode: 7500 Reward: -2045.081 Loss: 100.111
episode: 8000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-8000.pth
Episode: 8000 Reward: -2532.945 Loss: 75.142
episode: 8500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-8500.pth
Episode: 8500 Reward: -317.139 Loss: 58.481
episode: 9000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-9000.pth
Episode: 9000 Reward: -586.374 Loss: 90.170
episode: 9500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-9500.pth
Episode: 9500 Reward: -2488.731 Loss: 71.259
episode: 10000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-10000.pth
Episode: 10000 Reward: -326.593 Loss: 127.304
episode: 10500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-10500.pth
Episode: 10500 Reward: -674.508 Loss: 76.015
episode: 11000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-11000.pth
Episode: 11000 Reward: -338.532 Loss: 39.825
episode: 11500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-11500.pth
Episode: 11500 Reward: -313.212 Loss: 17.028
episode: 12000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-12000.pth
Episode: 12000 Reward: -375.885 Loss: 26.607
episode: 12500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-12500.pth
Episode: 12500 Reward: -1915.372 Loss: 53.309
episode: 13000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-13000.pth
Episode: 13000 Reward: -534.616 Loss: 34.303
episode: 13500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-13500.pth
Episode: 13500 Reward: -628.419 Loss: 48.812
episode: 14000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-14000.pth
Episode: 14000 Reward: -102.032 Loss: 44.239
episode: 14500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-14500.pth
Episode: 14500 Reward: -163.101 Loss: 45.812
episode: 15000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-15000.pth
Episode: 15000 Reward: -1560.104 Loss: 34.221
episode: 15500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-15500.pth
Episode: 15500 Reward: -215.141 Loss: 20.923
episode: 16000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-16000.pth
Episode: 16000 Reward: -126.846 Loss: 29.487
episode: 16500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-16500.pth
Episode: 16500 Reward: -819.730 Loss: 60.396
episode: 17000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-17000.pth
Episode: 17000 Reward: -296.940 Loss: 31.703
episode: 17500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-17500.pth
Episode: 17500 Reward: -119.238 Loss: 36.338
episode: 18000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-18000.pth
Episode: 18000 Reward: -89.603 Loss: 48.366
episode: 18500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-18500.pth
Episode: 18500 Reward: -28.916 Loss: 40.080
episode: 19000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-19000.pth
Episode: 19000 Reward: -1218.603 Loss: 43.187
episode: 19500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-19500.pth
Episode: 19500 Reward: -331.521 Loss: 40.409
episode: 20000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-20000.pth
Episode: 20000 Reward: -1391.291 Loss: 32.045
episode: 20500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-20500.pth
Episode: 20500 Reward: -62.241 Loss: 61.010
episode: 21000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-21000.pth
Episode: 21000 Reward: -21.544 Loss: 86.038
episode: 21500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-21500.pth
Episode: 21500 Reward: -79.406 Loss: 26.226
episode: 22000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-22000.pth
Episode: 22000 Reward: -68.735 Loss: 47.401
episode: 22500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-22500.pth
Episode: 22500 Reward: -139.011 Loss: 31.840
episode: 23000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-23000.pth
Episode: 23000 Reward: 40.196 Loss: 104.185
episode: 23500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-23500.pth
Episode: 23500 Reward: 1.474 Loss: 25.064
episode: 24000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-24000.pth
Episode: 24000 Reward: 75.255 Loss: 52.283
episode: 24500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-24500.pth
Episode: 24500 Reward: 86.809 Loss: 46.801
episode: 25000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-25000.pth
Episode: 25000 Reward: 72.049 Loss: 59.040
episode: 25500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-25500.pth
Episode: 25500 Reward: -18.986 Loss: 43.575
episode: 26000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-26000.pth
Episode: 26000 Reward: 122.505 Loss: 79.230
episode: 26500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-26500.pth
Episode: 26500 Reward: -340.939 Loss: 86.431
episode: 27000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-27000.pth
Episode: 27000 Reward: -1099.859 Loss: 100.806
episode: 27500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-27500.pth
Episode: 27500 Reward: -890.004 Loss: 53.686
episode: 28000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-28000.pth
Episode: 28000 Reward: 155.043 Loss: 84.398
episode: 28500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-28500.pth
Episode: 28500 Reward: -828.575 Loss: 100.442
episode: 29000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-29000.pth
Episode: 29000 Reward: -130.848 Loss: 38.115
episode: 29500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-29500.pth
Episode: 29500 Reward: 120.094 Loss: 51.444
episode: 30000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-30000.pth
Episode: 30000 Reward: -431.265 Loss: 42.366
episode: 30500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-30500.pth
Episode: 30500 Reward: -803.001 Loss: 64.054
episode: 31000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-31000.pth
Episode: 31000 Reward: -765.802 Loss: 47.020
episode: 31500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-31500.pth
Episode: 31500 Reward: 187.539 Loss: 52.766
episode: 32000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-32000.pth
Episode: 32000 Reward: 87.181 Loss: 83.952
episode: 32500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-32500.pth
Episode: 32500 Reward: -1052.758 Loss: 59.375
episode: 33000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-33000.pth
Episode: 33000 Reward: -272.752 Loss: 47.715
episode: 33500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-33500.pth
Episode: 33500 Reward: 174.293 Loss: 25.254
episode: 34000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-34000.pth
Episode: 34000 Reward: 181.300 Loss: 63.884
episode: 34500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-34500.pth
Episode: 34500 Reward: 240.298 Loss: 109.761
episode: 35000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-35000.pth
Episode: 35000 Reward: 254.750 Loss: 17.892
episode: 35500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-35500.pth
Episode: 35500 Reward: 113.041 Loss: 17.434
episode: 36000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-36000.pth
Episode: 36000 Reward: 287.036 Loss: 74.044
episode: 36500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-36500.pth
Episode: 36500 Reward: 231.572 Loss: 27.374
episode: 37000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-37000.pth
Episode: 37000 Reward: 247.115 Loss: 67.250
episode: 37500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-37500.pth
Episode: 37500 Reward: -787.709 Loss: 40.171
episode: 38000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-38000.pth
Episode: 38000 Reward: 253.348 Loss: 88.859
episode: 38500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-38500.pth
Episode: 38500 Reward: -1.755 Loss: 88.972
episode: 39000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-39000.pth
Episode: 39000 Reward: 165.190 Loss: 72.469
episode: 39500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-39500.pth
Episode: 39500 Reward: 312.600 Loss: 69.797
episode: 40000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-40000.pth
Episode: 40000 Reward: -396.641 Loss: 76.980
episode: 40500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-40500.pth
Episode: 40500 Reward: 241.948 Loss: 30.362
episode: 41000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-41000.pth
Episode: 41000 Reward: -131.022 Loss: 95.938
episode: 41500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-41500.pth
Episode: 41500 Reward: 311.070 Loss: 96.984
episode: 42000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-42000.pth
Episode: 42000 Reward: -67.680 Loss: 18.939
episode: 42500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-42500.pth
Episode: 42500 Reward: 203.284 Loss: 16.894
episode: 43000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-43000.pth
Episode: 43000 Reward: 276.455 Loss: 94.595
episode: 43500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-43500.pth
Episode: 43500 Reward: 296.711 Loss: 67.321
episode: 44000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-44000.pth
Episode: 44000 Reward: -691.090 Loss: 62.835
episode: 44500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-44500.pth
Episode: 44500 Reward: 271.192 Loss: 153.753
episode: 45000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-45000.pth
Episode: 45000 Reward: -68.921 Loss: 107.632
episode: 45500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-45500.pth
Episode: 45500 Reward: 340.567 Loss: 15.891
episode: 46000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-46000.pth
Episode: 46000 Reward: -93.822 Loss: 88.661
episode: 46500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-46500.pth
Episode: 46500 Reward: 329.588 Loss: 144.737
episode: 47000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-47000.pth
Episode: 47000 Reward: -338.517 Loss: 45.103
episode: 47500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-47500.pth
Episode: 47500 Reward: -631.068 Loss: 20.259
episode: 48000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-48000.pth
Episode: 48000 Reward: 372.001 Loss: 50.462
episode: 48500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-48500.pth
Episode: 48500 Reward: 24.024 Loss: 73.894
episode: 49000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-49000.pth
Episode: 49000 Reward: -273.331 Loss: 30.612
episode: 49500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-49500.pth
Episode: 49500 Reward: 343.848 Loss: 10.403
episode: 50000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-50000.pth
Episode: 50000 Reward: -156.687 Loss: 14.135
episode: 50500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-50500.pth
Episode: 50500 Reward: 414.448 Loss: 23.201
episode: 51000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-51000.pth
Episode: 51000 Reward: 422.754 Loss: 19.911
episode: 51500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-51500.pth
Episode: 51500 Reward: 358.426 Loss: 26.884
episode: 52000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-52000.pth
Episode: 52000 Reward: 345.128 Loss: 28.594
episode: 52500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-52500.pth
Episode: 52500 Reward: 16.340 Loss: 13.686
episode: 53000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-53000.pth
Episode: 53000 Reward: 367.967 Loss: 136.547
episode: 53500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-53500.pth
Episode: 53500 Reward: 324.571 Loss: 27.750
episode: 54000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-54000.pth
Episode: 54000 Reward: 437.866 Loss: 182.546
episode: 54500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-54500.pth
Episode: 54500 Reward: 388.574 Loss: 94.116
episode: 55000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-55000.pth
Episode: 55000 Reward: 355.348 Loss: 84.198
episode: 55500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-55500.pth
Episode: 55500 Reward: 395.858 Loss: 64.874
episode: 56000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-56000.pth
Episode: 56000 Reward: 432.436 Loss: 198.063
episode: 56500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-56500.pth
Episode: 56500 Reward: 473.375 Loss: 22.080
episode: 57000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-57000.pth
Episode: 57000 Reward: -60.492 Loss: 46.048
episode: 57500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-57500.pth
Episode: 57500 Reward: 563.965 Loss: 93.454
episode: 58000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-58000.pth
Episode: 58000 Reward: 304.126 Loss: 135.048
episode: 58500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-58500.pth
Episode: 58500 Reward: 150.338 Loss: 176.139
episode: 59000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-59000.pth
Episode: 59000 Reward: 447.929 Loss: 126.572
episode: 59500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-59500.pth
Episode: 59500 Reward: 415.354 Loss: 133.573
episode: 60000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-60000.pth
Episode: 60000 Reward: 347.327 Loss: 19.985
episode: 60500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-60500.pth
Episode: 60500 Reward: -122.512 Loss: 82.700
episode: 61000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-61000.pth
Episode: 61000 Reward: 399.931 Loss: 65.220
episode: 61500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-61500.pth
Episode: 61500 Reward: 356.613 Loss: 14.597
episode: 62000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-62000.pth
Episode: 62000 Reward: 445.796 Loss: 69.571
episode: 62500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-62500.pth
Episode: 62500 Reward: 427.662 Loss: 102.018
episode: 63000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-63000.pth
Episode: 63000 Reward: 425.555 Loss: 74.739
episode: 63500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-63500.pth
Episode: 63500 Reward: 281.551 Loss: 12.842
episode: 64000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-64000.pth
Episode: 64000 Reward: 302.865 Loss: 15.036
episode: 64500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-64500.pth
Episode: 64500 Reward: 587.076 Loss: 131.541
episode: 65000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-65000.pth
Episode: 65000 Reward: -402.699 Loss: 96.386
episode: 65500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-65500.pth
Episode: 65500 Reward: 402.749 Loss: 16.003
episode: 66000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-66000.pth
Episode: 66000 Reward: 338.862 Loss: 168.624
episode: 66500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-66500.pth
Episode: 66500 Reward: 208.940 Loss: 17.179
episode: 67000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-67000.pth
Episode: 67000 Reward: 533.449 Loss: 85.390
episode: 67500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-67500.pth
Episode: 67500 Reward: 284.718 Loss: 14.661
episode: 68000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-68000.pth
Episode: 68000 Reward: 608.233 Loss: 163.103
episode: 68500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-68500.pth
Episode: 68500 Reward: 610.300 Loss: 23.388
episode: 69000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-69000.pth
Episode: 69000 Reward: 424.962 Loss: 143.012
episode: 69500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-69500.pth
Episode: 69500 Reward: 352.857 Loss: 158.889
episode: 70000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-70000.pth
Episode: 70000 Reward: 442.826 Loss: 86.879
episode: 70500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-70500.pth
Episode: 70500 Reward: 605.955 Loss: 94.603
episode: 71000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-71000.pth
Episode: 71000 Reward: 312.215 Loss: 51.243
episode: 71500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-71500.pth
Episode: 71500 Reward: 650.220 Loss: 183.734
episode: 72000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-72000.pth
Episode: 72000 Reward: 249.875 Loss: 134.548
episode: 72500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-72500.pth
Episode: 72500 Reward: 186.304 Loss: 76.768
episode: 73000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-73000.pth
Episode: 73000 Reward: -285.442 Loss: 73.586
episode: 73500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-73500.pth
Episode: 73500 Reward: 338.718 Loss: 168.644
episode: 74000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-74000.pth
Episode: 74000 Reward: 22.769 Loss: 73.302
episode: 74500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-74500.pth
Episode: 74500 Reward: 395.692 Loss: 110.899
episode: 75000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-75000.pth
Episode: 75000 Reward: 232.659 Loss: 312.763
episode: 75500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-75500.pth
Episode: 75500 Reward: 185.290 Loss: 27.198
episode: 76000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-76000.pth
Episode: 76000 Reward: 673.266 Loss: 17.119
episode: 76500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-76500.pth
Episode: 76500 Reward: 411.365 Loss: 75.137
episode: 77000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-77000.pth
Episode: 77000 Reward: 461.360 Loss: 23.648
episode: 77500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-77500.pth
Episode: 77500 Reward: 121.781 Loss: 21.071
episode: 78000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-78000.pth
Episode: 78000 Reward: 734.076 Loss: 89.681
episode: 78500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-78500.pth
Episode: 78500 Reward: 413.478 Loss: 24.731
episode: 79000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-79000.pth
Episode: 79000 Reward: 241.290 Loss: 17.442
episode: 79500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-79500.pth
Episode: 79500 Reward: 278.666 Loss: 25.696
episode: 80000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-80000.pth
Episode: 80000 Reward: 84.967 Loss: 13.465
episode: 80500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-80500.pth
Episode: 80500 Reward: 738.943 Loss: 152.986
episode: 81000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-81000.pth
Episode: 81000 Reward: 531.363 Loss: 57.790
episode: 81500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-81500.pth
Episode: 81500 Reward: 596.609 Loss: 71.686
episode: 82000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-82000.pth
Episode: 82000 Reward: 462.049 Loss: 14.242
episode: 82500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-82500.pth
Episode: 82500 Reward: 294.700 Loss: 42.959
episode: 83000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-83000.pth
Episode: 83000 Reward: 504.041 Loss: 79.419
episode: 83500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-83500.pth
Episode: 83500 Reward: 501.724 Loss: 103.281
episode: 84000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-84000.pth
Episode: 84000 Reward: 737.125 Loss: 118.213
episode: 84500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-84500.pth
Episode: 84500 Reward: 531.080 Loss: 25.970
episode: 85000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-85000.pth
Episode: 85000 Reward: -149.328 Loss: 124.951
episode: 85500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-85500.pth
Episode: 85500 Reward: 578.697 Loss: 21.205
episode: 86000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-86000.pth
Episode: 86000 Reward: -37.046 Loss: 24.228
episode: 86500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-86500.pth
Episode: 86500 Reward: 546.713 Loss: 281.830
episode: 87000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-87000.pth
Episode: 87000 Reward: 517.929 Loss: 106.231
episode: 87500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-87500.pth
Episode: 87500 Reward: 495.303 Loss: 119.838
episode: 88000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-88000.pth
Episode: 88000 Reward: 667.172 Loss: 14.334
episode: 88500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-88500.pth
Episode: 88500 Reward: 637.163 Loss: 13.564
episode: 89000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-89000.pth
Episode: 89000 Reward: 599.348 Loss: 69.291
episode: 89500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-89500.pth
Episode: 89500 Reward: 406.138 Loss: 169.355
episode: 90000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-90000.pth
Episode: 90000 Reward: 368.908 Loss: 61.023
episode: 90500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-90500.pth
Episode: 90500 Reward: 744.198 Loss: 17.039
episode: 91000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-91000.pth
Episode: 91000 Reward: 712.745 Loss: 11.203
episode: 91500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-91500.pth
Episode: 91500 Reward: 333.365 Loss: 78.922
episode: 92000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-92000.pth
Episode: 92000 Reward: 431.219 Loss: 165.562
episode: 92500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-92500.pth
Episode: 92500 Reward: 113.715 Loss: 75.537
episode: 93000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-93000.pth
Episode: 93000 Reward: 195.886 Loss: 21.537
episode: 93500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-93500.pth
Episode: 93500 Reward: 714.760 Loss: 79.584
episode: 94000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-94000.pth
Episode: 94000 Reward: 468.485 Loss: 189.556
episode: 94500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-94500.pth
Episode: 94500 Reward: 75.020 Loss: 23.135
episode: 95000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-95000.pth
Episode: 95000 Reward: 404.735 Loss: 53.514
episode: 95500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-95500.pth
Episode: 95500 Reward: 567.677 Loss: 34.035
episode: 96000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-96000.pth
Episode: 96000 Reward: 588.824 Loss: 72.835
episode: 96500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-96500.pth
Episode: 96500 Reward: 378.997 Loss: 21.824
episode: 97000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-97000.pth
Episode: 97000 Reward: 485.059 Loss: 67.553
episode: 97500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-97500.pth
Episode: 97500 Reward: 361.891 Loss: 245.776
episode: 98000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-98000.pth
Episode: 98000 Reward: 562.432 Loss: 11.636
episode: 98500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-98500.pth
Episode: 98500 Reward: -97.176 Loss: 111.233
episode: 99000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-99000.pth
Episode: 99000 Reward: 684.778 Loss: 58.462
episode: 99500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-99500.pth
Episode: 99500 Reward: -104.747 Loss: 68.480
episode: 100000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-100000.pth
Episode: 100000 Reward: 473.589 Loss: 89.958
