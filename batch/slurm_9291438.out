player initial finish
Episode starts from:  1
episode: 500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-500.pth
Episode: 500 Reward: -632.192 Loss: 34.045
episode: 1000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-1000.pth
Episode: 1000 Reward: -661.973 Loss: 25.376
episode: 1500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-1500.pth
Episode: 1500 Reward: -1030.750 Loss: 42.706
episode: 2000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-2000.pth
Episode: 2000 Reward: -1501.272 Loss: 125.251
episode: 2500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-2500.pth
Episode: 2500 Reward: -965.410 Loss: 35.108
episode: 3000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-3000.pth
Episode: 3000 Reward: -3679.712 Loss: 74.599
episode: 3500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-3500.pth
Episode: 3500 Reward: -1289.970 Loss: 62.284
episode: 4000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-4000.pth
Episode: 4000 Reward: -355.066 Loss: 45.498
episode: 4500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-4500.pth
Episode: 4500 Reward: -440.653 Loss: 24.589
episode: 5000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-5000.pth
Episode: 5000 Reward: -574.968 Loss: 41.112
episode: 5500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-5500.pth
Episode: 5500 Reward: -466.651 Loss: 96.952
episode: 6000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-6000.pth
Episode: 6000 Reward: -2335.038 Loss: 87.357
episode: 6500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-6500.pth
Episode: 6500 Reward: -485.238 Loss: 34.033
episode: 7000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-7000.pth
Episode: 7000 Reward: -923.172 Loss: 98.665
episode: 7500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-7500.pth
Episode: 7500 Reward: -962.023 Loss: 41.396
episode: 8000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-8000.pth
Episode: 8000 Reward: -438.981 Loss: 91.206
episode: 8500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-8500.pth
Episode: 8500 Reward: -901.560 Loss: 82.581
episode: 9000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-9000.pth
Episode: 9000 Reward: -1021.485 Loss: 61.482
episode: 9500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-9500.pth
Episode: 9500 Reward: -351.882 Loss: 68.557
episode: 10000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-10000.pth
Episode: 10000 Reward: -3199.726 Loss: 91.849
episode: 10500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-10500.pth
Episode: 10500 Reward: -397.531 Loss: 19.458
episode: 11000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-11000.pth
Episode: 11000 Reward: -336.080 Loss: 95.955
episode: 11500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-11500.pth
Episode: 11500 Reward: -666.589 Loss: 37.387
episode: 12000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-12000.pth
Episode: 12000 Reward: -364.469 Loss: 25.359
episode: 12500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-12500.pth
Episode: 12500 Reward: -355.939 Loss: 136.236
episode: 13000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-13000.pth
Episode: 13000 Reward: -511.758 Loss: 53.256
episode: 13500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-13500.pth
Episode: 13500 Reward: -505.037 Loss: 51.134
episode: 14000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-14000.pth
Episode: 14000 Reward: -733.170 Loss: 38.513
episode: 14500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-14500.pth
Episode: 14500 Reward: -606.378 Loss: 47.230
episode: 15000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-15000.pth
Episode: 15000 Reward: -323.834 Loss: 30.615
episode: 15500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-15500.pth
Episode: 15500 Reward: -215.831 Loss: 62.951
episode: 16000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-16000.pth
Episode: 16000 Reward: -224.240 Loss: 73.287
episode: 16500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-16500.pth
Episode: 16500 Reward: -267.225 Loss: 91.592
episode: 17000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-17000.pth
Episode: 17000 Reward: -617.824 Loss: 64.099
episode: 17500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-17500.pth
Episode: 17500 Reward: -164.336 Loss: 64.472
episode: 18000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-18000.pth
Episode: 18000 Reward: -1158.748 Loss: 64.745
episode: 18500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-18500.pth
Episode: 18500 Reward: -265.012 Loss: 105.067
episode: 19000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-19000.pth
Episode: 19000 Reward: -2400.824 Loss: 55.880
episode: 19500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-19500.pth
Episode: 19500 Reward: -1626.896 Loss: 49.568
episode: 20000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-20000.pth
Episode: 20000 Reward: -2358.722 Loss: 41.401
episode: 20500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-20500.pth
Episode: 20500 Reward: -289.617 Loss: 173.084
episode: 21000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-21000.pth
Episode: 21000 Reward: -1870.961 Loss: 83.285
episode: 21500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-21500.pth
Episode: 21500 Reward: -440.014 Loss: 36.020
episode: 22000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-22000.pth
Episode: 22000 Reward: -1264.538 Loss: 60.119
episode: 22500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-22500.pth
Episode: 22500 Reward: -938.236 Loss: 98.279
episode: 23000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-23000.pth
Episode: 23000 Reward: -1671.270 Loss: 129.140
episode: 23500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-23500.pth
Episode: 23500 Reward: -50.745 Loss: 37.084
episode: 24000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-24000.pth
Episode: 24000 Reward: -115.594 Loss: 47.957
episode: 24500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-24500.pth
Episode: 24500 Reward: -11.842 Loss: 73.686
episode: 25000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-25000.pth
Episode: 25000 Reward: -59.668 Loss: 33.854
episode: 25500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-25500.pth
Episode: 25500 Reward: -1282.053 Loss: 67.528
episode: 26000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-26000.pth
Episode: 26000 Reward: -353.012 Loss: 52.993
episode: 26500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-26500.pth
Episode: 26500 Reward: -1084.141 Loss: 21.667
episode: 27000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-27000.pth
Episode: 27000 Reward: -374.095 Loss: 52.489
episode: 27500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-27500.pth
Episode: 27500 Reward: -1363.399 Loss: 64.116
episode: 28000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-28000.pth
Episode: 28000 Reward: 79.833 Loss: 70.409
episode: 28500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-28500.pth
Episode: 28500 Reward: 19.161 Loss: 18.005
episode: 29000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-29000.pth
Episode: 29000 Reward: -772.235 Loss: 87.133
episode: 29500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-29500.pth
Episode: 29500 Reward: 28.702 Loss: 87.917
episode: 30000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-30000.pth
Episode: 30000 Reward: 26.923 Loss: 83.714
episode: 30500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-30500.pth
Episode: 30500 Reward: 97.716 Loss: 45.561
episode: 31000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-31000.pth
Episode: 31000 Reward: 58.042 Loss: 44.732
episode: 31500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-31500.pth
Episode: 31500 Reward: -1425.383 Loss: 56.175
episode: 32000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-32000.pth
Episode: 32000 Reward: 166.566 Loss: 67.110
episode: 32500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-32500.pth
Episode: 32500 Reward: 55.420 Loss: 88.594
episode: 33000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-33000.pth
Episode: 33000 Reward: -4.987 Loss: 72.846
episode: 33500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-33500.pth
Episode: 33500 Reward: -1032.136 Loss: 40.576
episode: 34000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-34000.pth
Episode: 34000 Reward: 251.391 Loss: 31.554
episode: 34500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-34500.pth
Episode: 34500 Reward: 168.132 Loss: 35.226
episode: 35000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-35000.pth
Episode: 35000 Reward: 135.874 Loss: 73.588
episode: 35500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-35500.pth
Episode: 35500 Reward: -460.501 Loss: 51.041
episode: 36000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-36000.pth
Episode: 36000 Reward: 30.926 Loss: 70.731
episode: 36500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-36500.pth
Episode: 36500 Reward: -118.706 Loss: 75.390
episode: 37000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-37000.pth
Episode: 37000 Reward: 54.707 Loss: 130.868
episode: 37500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-37500.pth
Episode: 37500 Reward: -111.473 Loss: 57.132
episode: 38000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-38000.pth
Episode: 38000 Reward: 266.782 Loss: 18.411
episode: 38500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-38500.pth
Episode: 38500 Reward: -1418.798 Loss: 74.535
episode: 39000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-39000.pth
Episode: 39000 Reward: 149.183 Loss: 93.354
episode: 39500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-39500.pth
Episode: 39500 Reward: -1010.282 Loss: 119.924
episode: 40000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-40000.pth
Episode: 40000 Reward: -127.940 Loss: 87.178
episode: 40500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-40500.pth
Episode: 40500 Reward: -387.241 Loss: 26.544
episode: 41000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-41000.pth
Episode: 41000 Reward: 228.256 Loss: 12.207
episode: 41500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-41500.pth
Episode: 41500 Reward: 17.888 Loss: 91.636
episode: 42000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-42000.pth
Episode: 42000 Reward: 283.126 Loss: 53.954
episode: 42500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-42500.pth
Episode: 42500 Reward: -103.005 Loss: 95.425
episode: 43000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-43000.pth
Episode: 43000 Reward: 282.219 Loss: 33.599
episode: 43500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-43500.pth
Episode: 43500 Reward: -551.666 Loss: 19.626
episode: 44000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-44000.pth
Episode: 44000 Reward: -906.383 Loss: 113.963
episode: 44500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-44500.pth
Episode: 44500 Reward: -878.000 Loss: 70.190
episode: 45000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-45000.pth
Episode: 45000 Reward: 292.510 Loss: 75.790
episode: 45500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-45500.pth
Episode: 45500 Reward: -313.318 Loss: 85.217
episode: 46000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-46000.pth
Episode: 46000 Reward: -251.415 Loss: 55.829
episode: 46500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-46500.pth
Episode: 46500 Reward: 305.870 Loss: 31.416
episode: 47000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-47000.pth
Episode: 47000 Reward: 246.727 Loss: 37.731
episode: 47500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-47500.pth
Episode: 47500 Reward: 328.026 Loss: 73.214
episode: 48000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-48000.pth
Episode: 48000 Reward: 389.310 Loss: 63.839
episode: 48500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-48500.pth
Episode: 48500 Reward: -505.758 Loss: 26.821
episode: 49000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-49000.pth
Episode: 49000 Reward: 222.153 Loss: 16.652
episode: 49500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-49500.pth
Episode: 49500 Reward: 285.066 Loss: 41.576
episode: 50000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-50000.pth
Episode: 50000 Reward: 369.815 Loss: 143.278
episode: 50500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-50500.pth
Episode: 50500 Reward: 315.198 Loss: 14.269
episode: 51000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-51000.pth
Episode: 51000 Reward: 307.783 Loss: 18.272
episode: 51500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-51500.pth
Episode: 51500 Reward: 371.160 Loss: 63.273
episode: 52000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-52000.pth
Episode: 52000 Reward: 187.762 Loss: 71.020
episode: 52500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-52500.pth
Episode: 52500 Reward: 191.158 Loss: 85.180
episode: 53000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-53000.pth
Episode: 53000 Reward: 426.736 Loss: 15.652
episode: 53500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-53500.pth
Episode: 53500 Reward: 312.073 Loss: 71.320
episode: 54000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-54000.pth
Episode: 54000 Reward: 229.193 Loss: 24.227
episode: 54500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-54500.pth
Episode: 54500 Reward: 79.537 Loss: 36.989
episode: 55000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-55000.pth
Episode: 55000 Reward: -89.225 Loss: 23.395
episode: 55500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-55500.pth
Episode: 55500 Reward: -330.651 Loss: 117.281
episode: 56000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-56000.pth
Episode: 56000 Reward: 415.950 Loss: 24.212
episode: 56500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-56500.pth
Episode: 56500 Reward: -52.579 Loss: 14.891
episode: 57000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-57000.pth
Episode: 57000 Reward: 367.463 Loss: 50.887
episode: 57500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-57500.pth
Episode: 57500 Reward: -194.244 Loss: 125.936
episode: 58000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-58000.pth
Episode: 58000 Reward: -12.420 Loss: 43.614
episode: 58500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-58500.pth
Episode: 58500 Reward: -369.358 Loss: 30.614
episode: 59000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-59000.pth
Episode: 59000 Reward: 432.318 Loss: 65.489
episode: 59500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-59500.pth
Episode: 59500 Reward: 262.383 Loss: 90.093
episode: 60000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-60000.pth
Episode: 60000 Reward: 169.087 Loss: 11.159
episode: 60500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-60500.pth
Episode: 60500 Reward: 446.846 Loss: 43.204
episode: 61000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-61000.pth
Episode: 61000 Reward: 374.926 Loss: 27.108
episode: 61500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-61500.pth
Episode: 61500 Reward: 425.153 Loss: 158.763
episode: 62000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-62000.pth
Episode: 62000 Reward: 422.156 Loss: 12.771
episode: 62500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-62500.pth
Episode: 62500 Reward: 376.553 Loss: 20.675
episode: 63000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-63000.pth
Episode: 63000 Reward: 519.162 Loss: 148.195
episode: 63500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-63500.pth
Episode: 63500 Reward: -394.711 Loss: 46.284
episode: 64000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-64000.pth
Episode: 64000 Reward: -414.926 Loss: 71.636
episode: 64500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-64500.pth
Episode: 64500 Reward: 321.560 Loss: 70.596
episode: 65000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-65000.pth
Episode: 65000 Reward: 454.972 Loss: 19.286
episode: 65500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-65500.pth
Episode: 65500 Reward: 230.977 Loss: 37.606
episode: 66000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-66000.pth
Episode: 66000 Reward: 173.461 Loss: 107.728
episode: 66500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-66500.pth
Episode: 66500 Reward: 350.995 Loss: 10.291
episode: 67000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-67000.pth
Episode: 67000 Reward: 327.959 Loss: 23.606
episode: 67500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-67500.pth
Episode: 67500 Reward: -170.675 Loss: 145.283
episode: 68000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-68000.pth
Episode: 68000 Reward: 147.741 Loss: 143.686
episode: 68500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-68500.pth
Episode: 68500 Reward: 417.677 Loss: 25.100
episode: 69000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-69000.pth
Episode: 69000 Reward: 291.309 Loss: 138.616
episode: 69500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-69500.pth
Episode: 69500 Reward: 482.469 Loss: 16.325
episode: 70000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-70000.pth
Episode: 70000 Reward: 534.759 Loss: 16.721
episode: 70500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-70500.pth
Episode: 70500 Reward: 478.898 Loss: 66.865
episode: 71000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-71000.pth
Episode: 71000 Reward: 485.629 Loss: 9.618
episode: 71500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-71500.pth
Episode: 71500 Reward: 579.297 Loss: 16.670
episode: 72000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-72000.pth
Episode: 72000 Reward: 14.788 Loss: 79.039
episode: 72500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-72500.pth
Episode: 72500 Reward: 158.740 Loss: 95.815
episode: 73000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-73000.pth
Episode: 73000 Reward: -305.089 Loss: 34.838
episode: 73500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-73500.pth
Episode: 73500 Reward: 530.187 Loss: 13.055
episode: 74000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-74000.pth
Episode: 74000 Reward: 531.236 Loss: 131.403
episode: 74500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-74500.pth
Episode: 74500 Reward: 489.676 Loss: 17.376
episode: 75000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-75000.pth
Episode: 75000 Reward: 463.507 Loss: 9.050
episode: 75500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-75500.pth
Episode: 75500 Reward: 429.489 Loss: 123.538
episode: 76000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-76000.pth
Episode: 76000 Reward: 481.019 Loss: 45.916
episode: 76500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-76500.pth
Episode: 76500 Reward: 52.861 Loss: 23.080
episode: 77000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-77000.pth
Episode: 77000 Reward: -219.002 Loss: 15.577
episode: 77500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-77500.pth
Episode: 77500 Reward: -137.106 Loss: 21.485
episode: 78000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-78000.pth
Episode: 78000 Reward: 62.302 Loss: 18.652
episode: 78500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-78500.pth
Episode: 78500 Reward: -44.397 Loss: 30.244
episode: 79000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-79000.pth
Episode: 79000 Reward: 472.307 Loss: 23.179
episode: 79500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-79500.pth
Episode: 79500 Reward: 480.096 Loss: 75.687
episode: 80000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-80000.pth
Episode: 80000 Reward: 205.324 Loss: 56.780
