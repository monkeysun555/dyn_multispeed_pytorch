player initial finish
=> Restore ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-5000.pth
Episode starts from:  5001
episode: 5500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-5500.pth
Episode: 5500 Reward: -342.273 Loss: 33.676
episode: 6000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-6000.pth
Episode: 6000 Reward: -473.398 Loss: 36.623
episode: 6500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-6500.pth
Episode: 6500 Reward: -554.926 Loss: 28.230
episode: 7000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-7000.pth
Episode: 7000 Reward: -268.358 Loss: 28.510
episode: 7500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-7500.pth
Episode: 7500 Reward: -270.725 Loss: 19.834
episode: 8000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-8000.pth
Episode: 8000 Reward: -341.325 Loss: 37.116
episode: 8500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-8500.pth
Episode: 8500 Reward: -286.608 Loss: 26.831
episode: 9000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-9000.pth
Episode: 9000 Reward: -277.070 Loss: 35.818
episode: 9500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-9500.pth
Episode: 9500 Reward: -314.499 Loss: 18.151
episode: 10000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-10000.pth
Episode: 10000 Reward: -1367.389 Loss: 53.878
episode: 10500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-10500.pth
Episode: 10500 Reward: -496.099 Loss: 37.615
episode: 11000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-11000.pth
Episode: 11000 Reward: -230.580 Loss: 29.577
episode: 11500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-11500.pth
Episode: 11500 Reward: -232.528 Loss: 49.149
episode: 12000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-12000.pth
Episode: 12000 Reward: -181.353 Loss: 36.667
episode: 12500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-12500.pth
Episode: 12500 Reward: -727.974 Loss: 35.893
episode: 13000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-13000.pth
Episode: 13000 Reward: -1256.358 Loss: 26.811
episode: 13500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-13500.pth
Episode: 13500 Reward: -264.535 Loss: 24.089
episode: 14000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-14000.pth
Episode: 14000 Reward: -236.845 Loss: 39.490
episode: 14500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-14500.pth
Episode: 14500 Reward: -113.915 Loss: 28.413
episode: 15000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-15000.pth
Episode: 15000 Reward: -968.592 Loss: 41.864
episode: 15500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-15500.pth
Episode: 15500 Reward: -144.111 Loss: 24.989
episode: 16000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-16000.pth
Episode: 16000 Reward: -190.291 Loss: 28.422
episode: 16500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-16500.pth
Episode: 16500 Reward: -86.806 Loss: 16.909
episode: 17000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-17000.pth
Episode: 17000 Reward: -171.075 Loss: 42.018
episode: 17500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-17500.pth
Episode: 17500 Reward: -281.221 Loss: 48.300
episode: 18000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-18000.pth
Episode: 18000 Reward: -186.346 Loss: 44.662
episode: 18500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-18500.pth
Episode: 18500 Reward: -118.986 Loss: 34.950
episode: 19000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-19000.pth
Episode: 19000 Reward: -600.970 Loss: 33.972
episode: 19500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-19500.pth
Episode: 19500 Reward: -159.791 Loss: 24.008
episode: 20000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-20000.pth
Episode: 20000 Reward: -98.423 Loss: 17.571
episode: 20500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-20500.pth
Episode: 20500 Reward: -65.658 Loss: 37.928
episode: 21000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-21000.pth
Episode: 21000 Reward: -147.279 Loss: 29.682
episode: 21500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-21500.pth
Episode: 21500 Reward: -266.825 Loss: 34.994
episode: 22000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-22000.pth
Episode: 22000 Reward: -956.469 Loss: 26.789
episode: 22500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-22500.pth
Episode: 22500 Reward: -347.181 Loss: 24.766
episode: 23000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-23000.pth
Episode: 23000 Reward: 0.899 Loss: 24.510
episode: 23500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-23500.pth
Episode: 23500 Reward: -84.329 Loss: 17.993
episode: 24000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-24000.pth
Episode: 24000 Reward: 54.204 Loss: 28.118
episode: 24500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-24500.pth
Episode: 24500 Reward: -73.610 Loss: 41.537
episode: 25000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-25000.pth
Episode: 25000 Reward: -243.408 Loss: 44.367
episode: 25500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-25500.pth
Episode: 25500 Reward: 24.950 Loss: 25.643
episode: 26000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-26000.pth
Episode: 26000 Reward: -267.287 Loss: 35.494
episode: 26500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-26500.pth
Episode: 26500 Reward: -57.418 Loss: 19.117
episode: 27000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-27000.pth
Episode: 27000 Reward: 8.741 Loss: 21.384
episode: 27500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-27500.pth
Episode: 27500 Reward: 131.701 Loss: 20.647
episode: 28000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-28000.pth
Episode: 28000 Reward: -51.733 Loss: 53.549
episode: 28500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-28500.pth
Episode: 28500 Reward: -424.005 Loss: 33.371
episode: 29000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-29000.pth
Episode: 29000 Reward: -481.498 Loss: 29.315
episode: 29500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-29500.pth
Episode: 29500 Reward: -304.632 Loss: 39.935
episode: 30000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-30000.pth
Episode: 30000 Reward: 59.979 Loss: 18.976
episode: 30500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-30500.pth
Episode: 30500 Reward: -70.842 Loss: 28.467
episode: 31000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-31000.pth
Episode: 31000 Reward: 15.535 Loss: 26.308
episode: 31500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-31500.pth
Episode: 31500 Reward: 57.939 Loss: 25.782
episode: 32000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-32000.pth
Episode: 32000 Reward: -180.343 Loss: 57.322
episode: 32500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-32500.pth
Episode: 32500 Reward: 60.612 Loss: 39.283
episode: 33000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-33000.pth
Episode: 33000 Reward: -616.222 Loss: 34.738
episode: 33500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-33500.pth
Episode: 33500 Reward: 121.707 Loss: 21.394
episode: 34000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-34000.pth
Episode: 34000 Reward: -50.965 Loss: 27.598
episode: 34500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-34500.pth
Episode: 34500 Reward: 5.884 Loss: 32.811
episode: 35000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-35000.pth
Episode: 35000 Reward: -204.571 Loss: 24.707
episode: 35500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-35500.pth
Episode: 35500 Reward: -24.595 Loss: 44.903
episode: 36000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-36000.pth
Episode: 36000 Reward: 106.861 Loss: 22.781
episode: 36500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-36500.pth
Episode: 36500 Reward: -34.704 Loss: 21.952
episode: 37000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-37000.pth
Episode: 37000 Reward: -77.795 Loss: 21.436
episode: 37500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-37500.pth
Episode: 37500 Reward: 213.059 Loss: 33.476
episode: 38000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-38000.pth
Episode: 38000 Reward: 89.929 Loss: 35.804
episode: 38500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-38500.pth
Episode: 38500 Reward: 158.287 Loss: 33.350
episode: 39000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-39000.pth
Episode: 39000 Reward: -17.828 Loss: 48.877
episode: 39500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-39500.pth
Episode: 39500 Reward: 119.732 Loss: 35.014
episode: 40000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-40000.pth
Episode: 40000 Reward: 122.940 Loss: 28.156
episode: 40500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-40500.pth
Episode: 40500 Reward: -345.244 Loss: 31.728
episode: 41000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-41000.pth
Episode: 41000 Reward: -314.770 Loss: 28.765
episode: 41500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-41500.pth
Episode: 41500 Reward: 125.207 Loss: 25.080
episode: 42000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-42000.pth
Episode: 42000 Reward: 243.040 Loss: 25.217
episode: 42500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-42500.pth
Episode: 42500 Reward: 152.106 Loss: 25.997
episode: 43000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-43000.pth
Episode: 43000 Reward: 14.917 Loss: 33.818
episode: 43500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-43500.pth
Episode: 43500 Reward: 272.166 Loss: 36.653
episode: 44000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-44000.pth
Episode: 44000 Reward: 148.097 Loss: 43.674
episode: 44500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-44500.pth
Episode: 44500 Reward: 111.218 Loss: 27.540
episode: 45000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-45000.pth
Episode: 45000 Reward: 123.523 Loss: 26.557
episode: 45500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-45500.pth
Episode: 45500 Reward: -36.667 Loss: 16.024
episode: 46000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-46000.pth
Episode: 46000 Reward: 198.871 Loss: 16.596
episode: 46500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-46500.pth
Episode: 46500 Reward: 12.194 Loss: 34.752
episode: 47000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-47000.pth
Episode: 47000 Reward: 283.696 Loss: 33.605
episode: 47500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-47500.pth
Episode: 47500 Reward: -427.132 Loss: 53.917
episode: 48000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-48000.pth
Episode: 48000 Reward: 312.949 Loss: 24.476
episode: 48500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-48500.pth
Episode: 48500 Reward: -496.038 Loss: 34.694
episode: 49000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-49000.pth
Episode: 49000 Reward: 100.284 Loss: 37.280
episode: 49500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-49500.pth
Episode: 49500 Reward: 367.831 Loss: 24.284
episode: 50000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-50000.pth
Episode: 50000 Reward: 160.514 Loss: 30.546
episode: 50500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-50500.pth
Episode: 50500 Reward: 255.818 Loss: 33.719
episode: 51000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-51000.pth
Episode: 51000 Reward: -315.244 Loss: 16.913
episode: 51500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-51500.pth
Episode: 51500 Reward: 101.463 Loss: 22.382
episode: 52000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-52000.pth
Episode: 52000 Reward: -70.960 Loss: 18.783
episode: 52500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-52500.pth
Episode: 52500 Reward: 301.600 Loss: 23.663
episode: 53000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-53000.pth
Episode: 53000 Reward: -76.661 Loss: 36.933
episode: 53500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-53500.pth
Episode: 53500 Reward: -320.659 Loss: 29.784
episode: 54000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-54000.pth
Episode: 54000 Reward: 347.477 Loss: 31.296
episode: 54500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-54500.pth
Episode: 54500 Reward: 282.116 Loss: 29.201
episode: 55000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-55000.pth
Episode: 55000 Reward: 202.229 Loss: 36.276
episode: 55500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-55500.pth
Episode: 55500 Reward: 86.148 Loss: 16.141
episode: 56000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-56000.pth
Episode: 56000 Reward: 90.825 Loss: 28.213
episode: 56500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-56500.pth
Episode: 56500 Reward: 65.952 Loss: 29.868
episode: 57000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-57000.pth
Episode: 57000 Reward: 259.884 Loss: 20.077
episode: 57500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-57500.pth
Episode: 57500 Reward: 215.580 Loss: 38.312
episode: 58000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-58000.pth
Episode: 58000 Reward: 87.752 Loss: 27.938
episode: 58500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-58500.pth
Episode: 58500 Reward: 324.354 Loss: 35.343
episode: 59000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-59000.pth
Episode: 59000 Reward: 206.503 Loss: 47.040
episode: 59500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-59500.pth
Episode: 59500 Reward: 75.941 Loss: 28.709
episode: 60000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-60000.pth
Episode: 60000 Reward: 323.248 Loss: 23.558
episode: 60500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-60500.pth
Episode: 60500 Reward: 26.446 Loss: 24.012
episode: 61000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-61000.pth
Episode: 61000 Reward: -195.252 Loss: 20.697
episode: 61500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-61500.pth
Episode: 61500 Reward: 311.165 Loss: 30.809
episode: 62000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-62000.pth
Episode: 62000 Reward: 217.832 Loss: 42.794
episode: 62500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-62500.pth
Episode: 62500 Reward: 270.294 Loss: 28.337
episode: 63000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-63000.pth
Episode: 63000 Reward: 243.979 Loss: 43.198
episode: 63500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-63500.pth
Episode: 63500 Reward: 229.342 Loss: 37.385
episode: 64000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-64000.pth
Episode: 64000 Reward: 357.796 Loss: 28.602
episode: 64500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-64500.pth
Episode: 64500 Reward: 272.167 Loss: 34.247
episode: 65000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-65000.pth
Episode: 65000 Reward: 136.869 Loss: 38.339
episode: 65500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-65500.pth
Episode: 65500 Reward: 376.441 Loss: 49.032
episode: 66000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-66000.pth
Episode: 66000 Reward: 241.887 Loss: 33.349
episode: 66500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-66500.pth
Episode: 66500 Reward: 301.894 Loss: 19.992
episode: 67000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-67000.pth
Episode: 67000 Reward: 247.944 Loss: 29.638
episode: 67500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-67500.pth
Episode: 67500 Reward: 163.923 Loss: 26.677
episode: 68000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-68000.pth
Episode: 68000 Reward: -51.656 Loss: 47.968
episode: 68500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-68500.pth
Episode: 68500 Reward: 468.600 Loss: 27.710
episode: 69000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-69000.pth
Episode: 69000 Reward: 62.088 Loss: 33.155
episode: 69500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-69500.pth
Episode: 69500 Reward: 61.472 Loss: 38.522
episode: 70000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-70000.pth
Episode: 70000 Reward: 309.305 Loss: 25.219
episode: 70500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-70500.pth
Episode: 70500 Reward: -54.305 Loss: 28.186
episode: 71000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-71000.pth
Episode: 71000 Reward: 287.278 Loss: 41.083
episode: 71500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-71500.pth
Episode: 71500 Reward: 266.424 Loss: 21.223
episode: 72000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-72000.pth
Episode: 72000 Reward: 450.972 Loss: 28.708
episode: 72500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-72500.pth
Episode: 72500 Reward: 280.044 Loss: 36.829
episode: 73000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-73000.pth
Episode: 73000 Reward: 416.361 Loss: 31.243
episode: 73500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-73500.pth
Episode: 73500 Reward: 304.713 Loss: 28.942
episode: 74000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-74000.pth
Episode: 74000 Reward: -382.620 Loss: 37.714
episode: 74500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-74500.pth
Episode: 74500 Reward: 84.217 Loss: 24.451
episode: 75000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-75000.pth
Episode: 75000 Reward: 469.051 Loss: 22.801
episode: 75500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-75500.pth
Episode: 75500 Reward: 486.627 Loss: 27.095
episode: 76000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-76000.pth
Episode: 76000 Reward: 291.587 Loss: 30.845
episode: 76500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-76500.pth
Episode: 76500 Reward: 303.974 Loss: 27.120
episode: 77000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-77000.pth
Episode: 77000 Reward: 318.003 Loss: 15.480
episode: 77500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-77500.pth
Episode: 77500 Reward: 418.693 Loss: 28.579
episode: 78000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-78000.pth
Episode: 78000 Reward: 365.058 Loss: 21.999
episode: 78500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-78500.pth
Episode: 78500 Reward: 361.911 Loss: 23.530
episode: 79000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-79000.pth
Episode: 79000 Reward: 74.745 Loss: 23.859
episode: 79500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-79500.pth
Episode: 79500 Reward: -0.363 Loss: 22.676
episode: 80000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-80000.pth
Episode: 80000 Reward: 234.442 Loss: 26.768
episode: 80500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-80500.pth
Episode: 80500 Reward: 404.616 Loss: 16.801
episode: 81000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-81000.pth
Episode: 81000 Reward: 382.601 Loss: 21.243
episode: 81500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-81500.pth
Episode: 81500 Reward: 75.440 Loss: 19.756
episode: 82000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-82000.pth
Episode: 82000 Reward: 275.849 Loss: 12.783
episode: 82500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-82500.pth
Episode: 82500 Reward: 281.533 Loss: 24.619
episode: 83000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-83000.pth
Episode: 83000 Reward: 19.611 Loss: 14.719
episode: 83500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-83500.pth
Episode: 83500 Reward: 385.700 Loss: 30.811
episode: 84000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-84000.pth
Episode: 84000 Reward: 333.417 Loss: 32.085
episode: 84500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-84500.pth
Episode: 84500 Reward: 185.885 Loss: 29.441
episode: 85000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-85000.pth
Episode: 85000 Reward: 320.437 Loss: 17.893
episode: 85500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-85500.pth
Episode: 85500 Reward: 252.929 Loss: 15.331
episode: 86000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-86000.pth
Episode: 86000 Reward: 289.185 Loss: 28.984
episode: 86500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-86500.pth
Episode: 86500 Reward: 395.065 Loss: 17.271
episode: 87000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-87000.pth
Episode: 87000 Reward: 128.662 Loss: 40.612
episode: 87500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-87500.pth
Episode: 87500 Reward: 191.096 Loss: 35.574
episode: 88000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-88000.pth
Episode: 88000 Reward: 308.403 Loss: 27.619
episode: 88500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-88500.pth
Episode: 88500 Reward: 66.656 Loss: 19.067
episode: 89000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-89000.pth
Episode: 89000 Reward: 323.267 Loss: 34.477
episode: 89500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-89500.pth
Episode: 89500 Reward: -58.981 Loss: 28.519
episode: 90000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-90000.pth
Episode: 90000 Reward: -32.590 Loss: 27.740
episode: 90500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-90500.pth
Episode: 90500 Reward: 352.126 Loss: 32.796
episode: 91000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-91000.pth
Episode: 91000 Reward: 484.163 Loss: 26.222
episode: 91500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-91500.pth
Episode: 91500 Reward: 262.619 Loss: 33.217
episode: 92000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-92000.pth
Episode: 92000 Reward: 349.632 Loss: 43.115
episode: 92500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-92500.pth
Episode: 92500 Reward: 371.720 Loss: 31.824
episode: 93000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-93000.pth
Episode: 93000 Reward: 365.085 Loss: 15.889
episode: 93500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-93500.pth
Episode: 93500 Reward: 28.360 Loss: 23.123
episode: 94000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-94000.pth
Episode: 94000 Reward: 525.992 Loss: 31.248
episode: 94500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-94500.pth
Episode: 94500 Reward: 172.500 Loss: 30.343
episode: 95000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-95000.pth
Episode: 95000 Reward: 458.818 Loss: 19.435
episode: 95500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-95500.pth
Episode: 95500 Reward: 299.238 Loss: 31.683
episode: 96000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-96000.pth
Episode: 96000 Reward: 212.851 Loss: 23.889
episode: 96500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-96500.pth
Episode: 96500 Reward: 447.653 Loss: 12.289
episode: 97000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-97000.pth
Episode: 97000 Reward: 449.727 Loss: 22.334
episode: 97500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-97500.pth
Episode: 97500 Reward: 328.779 Loss: 17.826
episode: 98000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-98000.pth
Episode: 98000 Reward: 290.490 Loss: 17.258
episode: 98500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-98500.pth
Episode: 98500 Reward: 375.852 Loss: 18.045
episode: 99000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-99000.pth
Episode: 99000 Reward: 338.775 Loss: 22.972
episode: 99500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-99500.pth
Episode: 99500 Reward: 391.940 Loss: 33.108
episode: 100000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_Nones_amplified/model-100000.pth
Episode: 100000 Reward: 381.172 Loss: 16.951
