player initial finish
=> Restore ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-70000.pth
episode: 70500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-70500.pth
Episode: 70500 Reward: 62.638 Loss: 22.185
episode: 71000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-71000.pth
Episode: 71000 Reward: 202.661 Loss: 17.905
episode: 71500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-71500.pth
Episode: 71500 Reward: 32.982 Loss: 19.423
episode: 72000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-72000.pth
Episode: 72000 Reward: 276.423 Loss: 16.054
episode: 72500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-72500.pth
Episode: 72500 Reward: 206.067 Loss: 32.028
episode: 73000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-73000.pth
Episode: 73000 Reward: 192.640 Loss: 24.573
episode: 73500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-73500.pth
Episode: 73500 Reward: 222.173 Loss: 28.151
episode: 74000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-74000.pth
Episode: 74000 Reward: 267.690 Loss: 27.913
episode: 74500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-74500.pth
Episode: 74500 Reward: 112.736 Loss: 34.203
episode: 75000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-75000.pth
Episode: 75000 Reward: 135.841 Loss: 30.019
episode: 75500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-75500.pth
Episode: 75500 Reward: 275.384 Loss: 24.267
episode: 76000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-76000.pth
Episode: 76000 Reward: 191.431 Loss: 42.272
episode: 76500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-76500.pth
Episode: 76500 Reward: 263.253 Loss: 41.721
episode: 77000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-77000.pth
Episode: 77000 Reward: 272.443 Loss: 24.561
episode: 77500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-77500.pth
Episode: 77500 Reward: 179.817 Loss: 41.255
episode: 78000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-78000.pth
Episode: 78000 Reward: 275.375 Loss: 34.646
episode: 78500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-78500.pth
Episode: 78500 Reward: 103.425 Loss: 29.764
episode: 79000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-79000.pth
Episode: 79000 Reward: 147.711 Loss: 32.450
episode: 79500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-79500.pth
Episode: 79500 Reward: 119.610 Loss: 26.596
episode: 80000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-80000.pth
Episode: 80000 Reward: 215.477 Loss: 28.107
episode: 80500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-80500.pth
Episode: 80500 Reward: 176.651 Loss: 27.487
episode: 81000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-81000.pth
Episode: 81000 Reward: 179.328 Loss: 35.588
episode: 81500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-81500.pth
Episode: 81500 Reward: 273.567 Loss: 24.473
episode: 82000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-82000.pth
Episode: 82000 Reward: 53.881 Loss: 28.684
episode: 82500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-82500.pth
Episode: 82500 Reward: 274.332 Loss: 24.220
episode: 83000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-83000.pth
Episode: 83000 Reward: 262.856 Loss: 30.588
episode: 83500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-83500.pth
Episode: 83500 Reward: 131.340 Loss: 24.119
episode: 84000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-84000.pth
Episode: 84000 Reward: 200.323 Loss: 27.692
episode: 84500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-84500.pth
Episode: 84500 Reward: 280.797 Loss: 41.232
episode: 85000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-85000.pth
Episode: 85000 Reward: 177.776 Loss: 43.524
episode: 85500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-85500.pth
Episode: 85500 Reward: 169.584 Loss: 38.037
episode: 86000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-86000.pth
Episode: 86000 Reward: 179.828 Loss: 31.611
episode: 86500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-86500.pth
Episode: 86500 Reward: 274.445 Loss: 20.217
episode: 87000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-87000.pth
Episode: 87000 Reward: 276.729 Loss: 30.748
episode: 87500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-87500.pth
Episode: 87500 Reward: 274.656 Loss: 34.539
episode: 88000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-88000.pth
Episode: 88000 Reward: 133.524 Loss: 15.971
episode: 88500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-88500.pth
Episode: 88500 Reward: 150.821 Loss: 23.858
episode: 89000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-89000.pth
Episode: 89000 Reward: 260.056 Loss: 25.832
episode: 89500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-89500.pth
Episode: 89500 Reward: 276.593 Loss: 29.441
episode: 90000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-90000.pth
Episode: 90000 Reward: 227.983 Loss: 28.672
episode: 90500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-90500.pth
Episode: 90500 Reward: 280.139 Loss: 21.443
episode: 91000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-91000.pth
Episode: 91000 Reward: 281.910 Loss: 31.820
episode: 91500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-91500.pth
Episode: 91500 Reward: 176.376 Loss: 35.255
episode: 92000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-92000.pth
Episode: 92000 Reward: 168.153 Loss: 31.073
episode: 92500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-92500.pth
Episode: 92500 Reward: 157.935 Loss: 30.209
episode: 93000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-93000.pth
Episode: 93000 Reward: 119.815 Loss: 26.056
episode: 93500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-93500.pth
Episode: 93500 Reward: 185.138 Loss: 33.884
episode: 94000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-94000.pth
Episode: 94000 Reward: 277.319 Loss: 24.274
episode: 94500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-94500.pth
Episode: 94500 Reward: 275.271 Loss: 30.919
episode: 95000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-95000.pth
Episode: 95000 Reward: 279.918 Loss: 36.813
episode: 95500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-95500.pth
Episode: 95500 Reward: 216.013 Loss: 30.839
episode: 96000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-96000.pth
Episode: 96000 Reward: 273.995 Loss: 28.576
episode: 96500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-96500.pth
Episode: 96500 Reward: -28.503 Loss: 31.863
episode: 97000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-97000.pth
Episode: 97000 Reward: 242.289 Loss: 22.778
episode: 97500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-97500.pth
Episode: 97500 Reward: 276.934 Loss: 21.219
episode: 98000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-98000.pth
Episode: 98000 Reward: 177.776 Loss: 34.698
episode: 98500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-98500.pth
Episode: 98500 Reward: 212.792 Loss: 24.953
episode: 99000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-99000.pth
Episode: 99000 Reward: 203.966 Loss: 26.635
episode: 99500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-99500.pth
Episode: 99500 Reward: 190.437 Loss: 25.498
episode: 100000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-100000.pth
Episode: 100000 Reward: 181.871 Loss: 22.742
