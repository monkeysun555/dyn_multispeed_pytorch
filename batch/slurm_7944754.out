player initial finish
=> Restore ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-15500.pth
episode: 16000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-16000.pth
Episode: 16000 Reward: 13.158 Loss: 37.138
episode: 16500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-16500.pth
Episode: 16500 Reward: -100.608 Loss: 40.908
episode: 17000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-17000.pth
Episode: 17000 Reward: -34.336 Loss: 36.026
episode: 17500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-17500.pth
Episode: 17500 Reward: 65.112 Loss: 32.828
episode: 18000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-18000.pth
Episode: 18000 Reward: 24.414 Loss: 38.726
episode: 18500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-18500.pth
Episode: 18500 Reward: -178.786 Loss: 51.400
episode: 19000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-19000.pth
Episode: 19000 Reward: -709.244 Loss: 56.475
episode: 19500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-19500.pth
Episode: 19500 Reward: 12.090 Loss: 49.992
episode: 20000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-20000.pth
Episode: 20000 Reward: 22.185 Loss: 44.111
episode: 20500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-20500.pth
Episode: 20500 Reward: -27.588 Loss: 45.402
episode: 21000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-21000.pth
Episode: 21000 Reward: -114.626 Loss: 47.050
episode: 21500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-21500.pth
Episode: 21500 Reward: 77.932 Loss: 49.087
episode: 22000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-22000.pth
Episode: 22000 Reward: -3.900 Loss: 31.796
episode: 22500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-22500.pth
Episode: 22500 Reward: 9.483 Loss: 43.170
episode: 23000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-23000.pth
Episode: 23000 Reward: -518.101 Loss: 41.232
episode: 23500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-23500.pth
Episode: 23500 Reward: 53.626 Loss: 32.150
episode: 24000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-24000.pth
Episode: 24000 Reward: 67.204 Loss: 39.186
episode: 24500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-24500.pth
Episode: 24500 Reward: -423.010 Loss: 54.701
episode: 25000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-25000.pth
Episode: 25000 Reward: 21.800 Loss: 41.491
episode: 25500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-25500.pth
Episode: 25500 Reward: 71.988 Loss: 35.882
episode: 26000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-26000.pth
Episode: 26000 Reward: 88.798 Loss: 40.244
episode: 26500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-26500.pth
Episode: 26500 Reward: 68.309 Loss: 55.022
episode: 27000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-27000.pth
Episode: 27000 Reward: -287.731 Loss: 38.038
episode: 27500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-27500.pth
Episode: 27500 Reward: 96.215 Loss: 38.581
episode: 28000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-28000.pth
Episode: 28000 Reward: 115.384 Loss: 46.046
episode: 28500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-28500.pth
Episode: 28500 Reward: 57.891 Loss: 28.020
episode: 29000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-29000.pth
Episode: 29000 Reward: -24.086 Loss: 39.480
episode: 29500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-29500.pth
Episode: 29500 Reward: 65.817 Loss: 35.591
episode: 30000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-30000.pth
Episode: 30000 Reward: 153.098 Loss: 55.154
episode: 30500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-30500.pth
Episode: 30500 Reward: -161.546 Loss: 50.822
episode: 31000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-31000.pth
Episode: 31000 Reward: 45.243 Loss: 44.931
episode: 31500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-31500.pth
Episode: 31500 Reward: -70.562 Loss: 57.405
episode: 32000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-32000.pth
Episode: 32000 Reward: -1.457 Loss: 58.441
episode: 32500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-32500.pth
Episode: 32500 Reward: 25.603 Loss: 63.657
episode: 33000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-33000.pth
Episode: 33000 Reward: 32.405 Loss: 27.640
episode: 33500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-33500.pth
Episode: 33500 Reward: 117.018 Loss: 59.477
episode: 34000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-34000.pth
Episode: 34000 Reward: 92.339 Loss: 64.897
episode: 34500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-34500.pth
Episode: 34500 Reward: 85.330 Loss: 30.026
episode: 35000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-35000.pth
Episode: 35000 Reward: -154.217 Loss: 44.018
episode: 35500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-35500.pth
Episode: 35500 Reward: 143.349 Loss: 58.940
episode: 36000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-36000.pth
Episode: 36000 Reward: -22.459 Loss: 53.678
episode: 36500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-36500.pth
Episode: 36500 Reward: 134.361 Loss: 48.851
episode: 37000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-37000.pth
Episode: 37000 Reward: 132.419 Loss: 38.883
episode: 37500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-37500.pth
Episode: 37500 Reward: 119.699 Loss: 49.685
episode: 38000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-38000.pth
Episode: 38000 Reward: 95.568 Loss: 37.805
episode: 38500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-38500.pth
Episode: 38500 Reward: 196.392 Loss: 46.501
episode: 39000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-39000.pth
Episode: 39000 Reward: 53.654 Loss: 50.730
episode: 39500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-39500.pth
Episode: 39500 Reward: 56.846 Loss: 42.968
episode: 40000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-40000.pth
Episode: 40000 Reward: -171.296 Loss: 38.796
episode: 40500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-40500.pth
Episode: 40500 Reward: 49.907 Loss: 35.744
episode: 41000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-41000.pth
Episode: 41000 Reward: 142.774 Loss: 43.997
episode: 41500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-41500.pth
Episode: 41500 Reward: -1.571 Loss: 44.724
episode: 42000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-42000.pth
Episode: 42000 Reward: 100.388 Loss: 29.547
episode: 42500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-42500.pth
Episode: 42500 Reward: 184.341 Loss: 51.858
episode: 43000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-43000.pth
Episode: 43000 Reward: 200.817 Loss: 28.575
episode: 43500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-43500.pth
Episode: 43500 Reward: 168.048 Loss: 34.433
episode: 44000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-44000.pth
Episode: 44000 Reward: 123.843 Loss: 35.161
episode: 44500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-44500.pth
Episode: 44500 Reward: 157.548 Loss: 34.211
episode: 45000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-45000.pth
Episode: 45000 Reward: 172.972 Loss: 39.726
episode: 45500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-45500.pth
Episode: 45500 Reward: 140.616 Loss: 29.958
episode: 46000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-46000.pth
Episode: 46000 Reward: 163.681 Loss: 41.088
episode: 46500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-46500.pth
Episode: 46500 Reward: 180.148 Loss: 42.404
episode: 47000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-47000.pth
Episode: 47000 Reward: -195.639 Loss: 31.855
episode: 47500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-47500.pth
Episode: 47500 Reward: 191.901 Loss: 47.298
episode: 48000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-48000.pth
Episode: 48000 Reward: 92.946 Loss: 38.613
episode: 48500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-48500.pth
Episode: 48500 Reward: 98.752 Loss: 39.965
episode: 49000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-49000.pth
Episode: 49000 Reward: 218.953 Loss: 27.672
episode: 49500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-49500.pth
Episode: 49500 Reward: 231.093 Loss: 42.063
episode: 50000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-50000.pth
Episode: 50000 Reward: -34.063 Loss: 53.341
episode: 50500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-50500.pth
Episode: 50500 Reward: 87.418 Loss: 26.615
episode: 51000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-51000.pth
Episode: 51000 Reward: 138.841 Loss: 32.064
episode: 51500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-51500.pth
Episode: 51500 Reward: 55.943 Loss: 39.117
episode: 52000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-52000.pth
Episode: 52000 Reward: 81.634 Loss: 36.048
episode: 52500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-52500.pth
Episode: 52500 Reward: 114.599 Loss: 28.063
episode: 53000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-53000.pth
Episode: 53000 Reward: 116.337 Loss: 24.841
episode: 53500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-53500.pth
Episode: 53500 Reward: -78.310 Loss: 28.966
episode: 54000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-54000.pth
Episode: 54000 Reward: -20.886 Loss: 48.637
episode: 54500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-54500.pth
Episode: 54500 Reward: 129.385 Loss: 48.228
episode: 55000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-55000.pth
Episode: 55000 Reward: 132.663 Loss: 37.929
episode: 55500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-55500.pth
Episode: 55500 Reward: 185.203 Loss: 27.832
episode: 56000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-56000.pth
Episode: 56000 Reward: 205.241 Loss: 39.321
episode: 56500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-56500.pth
Episode: 56500 Reward: 136.929 Loss: 39.557
episode: 57000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-57000.pth
Episode: 57000 Reward: 152.371 Loss: 37.544
episode: 57500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-57500.pth
Episode: 57500 Reward: 119.879 Loss: 47.005
episode: 58000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-58000.pth
Episode: 58000 Reward: 86.420 Loss: 38.798
episode: 58500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-58500.pth
Episode: 58500 Reward: -241.871 Loss: 44.673
episode: 59000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-59000.pth
Episode: 59000 Reward: 23.196 Loss: 55.972
episode: 59500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-59500.pth
Episode: 59500 Reward: 96.210 Loss: 35.599
episode: 60000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-60000.pth
Episode: 60000 Reward: -25.128 Loss: 43.240
episode: 60500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-60500.pth
Episode: 60500 Reward: 214.729 Loss: 32.883
episode: 61000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-61000.pth
Episode: 61000 Reward: -35.601 Loss: 33.653
episode: 61500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-61500.pth
Episode: 61500 Reward: 123.847 Loss: 35.664
episode: 62000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-62000.pth
Episode: 62000 Reward: 136.132 Loss: 31.299
episode: 62500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-62500.pth
Episode: 62500 Reward: 222.014 Loss: 39.096
episode: 63000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-63000.pth
Episode: 63000 Reward: 180.468 Loss: 38.820
episode: 63500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-63500.pth
Episode: 63500 Reward: 183.637 Loss: 44.970
episode: 64000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-64000.pth
Episode: 64000 Reward: 1.630 Loss: 38.535
episode: 64500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-64500.pth
Episode: 64500 Reward: 178.084 Loss: 42.275
episode: 65000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-65000.pth
Episode: 65000 Reward: 218.719 Loss: 43.316
episode: 65500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-65500.pth
Episode: 65500 Reward: 202.162 Loss: 43.179
episode: 66000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-66000.pth
Episode: 66000 Reward: 214.013 Loss: 35.196
episode: 66500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-66500.pth
Episode: 66500 Reward: 157.184 Loss: 31.030
episode: 67000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-67000.pth
Episode: 67000 Reward: 99.830 Loss: 29.983
episode: 67500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-67500.pth
Episode: 67500 Reward: 226.365 Loss: 37.772
episode: 68000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-68000.pth
Episode: 68000 Reward: 128.900 Loss: 30.669
episode: 68500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-68500.pth
Episode: 68500 Reward: 120.818 Loss: 28.940
episode: 69000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-69000.pth
Episode: 69000 Reward: 54.194 Loss: 33.384
episode: 69500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-69500.pth
Episode: 69500 Reward: -4.082 Loss: 30.736
episode: 70000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-70000.pth
Episode: 70000 Reward: 193.128 Loss: 38.713
episode: 70500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-70500.pth
Episode: 70500 Reward: 180.047 Loss: 31.528
episode: 71000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-71000.pth
Episode: 71000 Reward: 145.329 Loss: 39.817
episode: 71500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-71500.pth
Episode: 71500 Reward: 278.386 Loss: 44.072
episode: 72000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-72000.pth
Episode: 72000 Reward: -78.087 Loss: 36.212
episode: 72500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-72500.pth
Episode: 72500 Reward: 244.654 Loss: 27.631
episode: 73000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-73000.pth
Episode: 73000 Reward: 97.285 Loss: 51.488
episode: 73500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-73500.pth
Episode: 73500 Reward: 245.027 Loss: 31.394
episode: 74000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-74000.pth
Episode: 74000 Reward: 230.087 Loss: 40.358
episode: 74500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-74500.pth
Episode: 74500 Reward: 53.139 Loss: 43.109
episode: 75000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-75000.pth
Episode: 75000 Reward: 256.685 Loss: 53.093
episode: 75500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-75500.pth
Episode: 75500 Reward: 276.178 Loss: 39.093
episode: 76000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-76000.pth
Episode: 76000 Reward: 144.604 Loss: 30.015
episode: 76500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-76500.pth
Episode: 76500 Reward: 111.457 Loss: 29.857
episode: 77000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-77000.pth
Episode: 77000 Reward: 258.558 Loss: 30.868
episode: 77500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-77500.pth
Episode: 77500 Reward: 111.238 Loss: 30.751
episode: 78000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-78000.pth
Episode: 78000 Reward: 165.783 Loss: 24.745
episode: 78500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-78500.pth
Episode: 78500 Reward: 235.472 Loss: 37.518
episode: 79000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-79000.pth
Episode: 79000 Reward: 242.055 Loss: 26.425
episode: 79500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-79500.pth
Episode: 79500 Reward: 168.351 Loss: 37.303
episode: 80000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-80000.pth
Episode: 80000 Reward: 100.346 Loss: 27.730
episode: 80500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-80500.pth
Episode: 80500 Reward: 267.543 Loss: 31.639
episode: 81000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-81000.pth
Episode: 81000 Reward: 83.539 Loss: 34.156
episode: 81500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-81500.pth
Episode: 81500 Reward: 26.177 Loss: 42.269
episode: 82000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-82000.pth
Episode: 82000 Reward: -27.875 Loss: 37.403
episode: 82500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-82500.pth
Episode: 82500 Reward: 151.811 Loss: 31.223
episode: 83000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-83000.pth
Episode: 83000 Reward: 179.329 Loss: 33.884
episode: 83500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-83500.pth
Episode: 83500 Reward: 264.955 Loss: 21.954
episode: 84000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-84000.pth
Episode: 84000 Reward: 21.311 Loss: 24.449
episode: 84500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-84500.pth
Episode: 84500 Reward: -8.223 Loss: 30.738
episode: 85000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-85000.pth
Episode: 85000 Reward: 228.126 Loss: 37.269
episode: 85500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-85500.pth
Episode: 85500 Reward: 179.206 Loss: 45.927
episode: 86000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-86000.pth
Episode: 86000 Reward: 248.160 Loss: 38.436
episode: 86500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-86500.pth
Episode: 86500 Reward: 190.619 Loss: 24.721
episode: 87000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-87000.pth
Episode: 87000 Reward: 279.350 Loss: 32.219
episode: 87500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-87500.pth
Episode: 87500 Reward: 248.617 Loss: 41.551
episode: 88000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-88000.pth
Episode: 88000 Reward: 71.078 Loss: 46.375
episode: 88500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-88500.pth
Episode: 88500 Reward: 276.995 Loss: 28.106
episode: 89000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-89000.pth
Episode: 89000 Reward: 267.557 Loss: 47.095
episode: 89500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-89500.pth
Episode: 89500 Reward: 252.556 Loss: 43.682
episode: 90000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-90000.pth
Episode: 90000 Reward: 89.718 Loss: 41.783
episode: 90500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-90500.pth
Episode: 90500 Reward: 257.320 Loss: 45.364
episode: 91000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-91000.pth
Episode: 91000 Reward: 184.942 Loss: 45.559
episode: 91500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-91500.pth
Episode: 91500 Reward: 157.393 Loss: 30.918
episode: 92000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-92000.pth
Episode: 92000 Reward: 258.168 Loss: 31.557
episode: 92500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-92500.pth
Episode: 92500 Reward: 174.902 Loss: 24.742
episode: 93000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-93000.pth
Episode: 93000 Reward: 54.029 Loss: 29.221
episode: 93500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-93500.pth
Episode: 93500 Reward: 103.045 Loss: 25.941
episode: 94000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-94000.pth
Episode: 94000 Reward: 169.969 Loss: 24.200
episode: 94500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-94500.pth
Episode: 94500 Reward: 263.161 Loss: 27.652
episode: 95000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-95000.pth
Episode: 95000 Reward: 279.767 Loss: 20.326
episode: 95500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-95500.pth
Episode: 95500 Reward: 200.928 Loss: 27.074
episode: 96000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-96000.pth
Episode: 96000 Reward: 142.916 Loss: 25.560
episode: 96500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-96500.pth
Episode: 96500 Reward: 254.123 Loss: 33.526
episode: 97000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-97000.pth
Episode: 97000 Reward: 79.740 Loss: 22.554
episode: 97500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-97500.pth
Episode: 97500 Reward: 260.860 Loss: 31.165
episode: 98000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-98000.pth
Episode: 98000 Reward: 195.138 Loss: 30.226
episode: 98500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-98500.pth
Episode: 98500 Reward: 256.551 Loss: 37.620
episode: 99000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-99000.pth
Episode: 99000 Reward: 79.350 Loss: 22.554
episode: 99500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-99500.pth
Episode: 99500 Reward: 68.599 Loss: 31.651
episode: 100000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-100000.pth
Episode: 100000 Reward: 251.945 Loss: 31.742
