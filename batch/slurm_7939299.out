player initial finish
episode: 500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-500.pth
Episode: 500 Reward: -356.467 Loss: 20.102
episode: 1000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-1000.pth
Episode: 1000 Reward: -239.857 Loss: 21.472
episode: 1500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-1500.pth
Episode: 1500 Reward: -235.242 Loss: 36.875
episode: 2000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-2000.pth
Episode: 2000 Reward: -202.360 Loss: 25.605
episode: 2500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-2500.pth
Episode: 2500 Reward: -173.799 Loss: 47.185
episode: 3000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-3000.pth
Episode: 3000 Reward: -212.648 Loss: 41.300
episode: 3500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-3500.pth
Episode: 3500 Reward: -117.756 Loss: 39.349
episode: 4000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-4000.pth
Episode: 4000 Reward: -106.698 Loss: 40.372
episode: 4500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-4500.pth
Episode: 4500 Reward: -194.765 Loss: 32.346
episode: 5000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-5000.pth
Episode: 5000 Reward: -183.429 Loss: 55.258
episode: 5500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-5500.pth
Episode: 5500 Reward: -157.403 Loss: 73.892
episode: 6000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-6000.pth
Episode: 6000 Reward: -134.426 Loss: 44.789
episode: 6500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-6500.pth
Episode: 6500 Reward: -422.504 Loss: 36.002
episode: 7000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-7000.pth
Episode: 7000 Reward: -348.281 Loss: 35.185
episode: 7500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-7500.pth
Episode: 7500 Reward: -66.151 Loss: 61.564
episode: 8000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-8000.pth
Episode: 8000 Reward: -91.251 Loss: 51.572
episode: 8500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-8500.pth
Episode: 8500 Reward: -165.264 Loss: 40.838
episode: 9000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-9000.pth
Episode: 9000 Reward: -133.342 Loss: 67.546
episode: 9500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-9500.pth
Episode: 9500 Reward: -574.359 Loss: 55.746
episode: 10000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-10000.pth
Episode: 10000 Reward: -128.619 Loss: 47.855
episode: 10500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-10500.pth
Episode: 10500 Reward: -24.751 Loss: 66.661
episode: 11000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-11000.pth
Episode: 11000 Reward: -108.539 Loss: 48.229
episode: 11500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-11500.pth
Episode: 11500 Reward: -156.563 Loss: 49.982
episode: 12000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-12000.pth
Episode: 12000 Reward: -223.067 Loss: 47.352
episode: 12500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-12500.pth
Episode: 12500 Reward: -83.168 Loss: 46.214
episode: 13000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-13000.pth
Episode: 13000 Reward: -44.188 Loss: 46.344
episode: 13500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-13500.pth
Episode: 13500 Reward: -70.966 Loss: 44.247
episode: 14000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-14000.pth
Episode: 14000 Reward: 16.184 Loss: 59.016
episode: 14500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-14500.pth
Episode: 14500 Reward: -236.339 Loss: 55.316
episode: 15000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-15000.pth
Episode: 15000 Reward: -3.740 Loss: 36.664
episode: 15500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-15500.pth
Episode: 15500 Reward: 13.878 Loss: 32.771
episode: 16000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-16000.pth
Episode: 16000 Reward: -5.169 Loss: 36.962
episode: 16500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-16500.pth
Episode: 16500 Reward: -37.926 Loss: 38.797
episode: 17000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-17000.pth
Episode: 17000 Reward: 13.626 Loss: 42.678
episode: 17500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-17500.pth
Episode: 17500 Reward: 5.582 Loss: 42.721
episode: 18000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-18000.pth
Episode: 18000 Reward: -2.209 Loss: 43.298
episode: 18500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-18500.pth
Episode: 18500 Reward: 9.139 Loss: 35.651
episode: 19000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-19000.pth
Episode: 19000 Reward: -20.304 Loss: 31.350
episode: 19500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-19500.pth
Episode: 19500 Reward: -366.017 Loss: 24.858
episode: 20000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-20000.pth
Episode: 20000 Reward: -20.030 Loss: 40.668
episode: 20500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-20500.pth
Episode: 20500 Reward: 48.715 Loss: 32.719
episode: 21000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-21000.pth
Episode: 21000 Reward: -344.214 Loss: 30.029
episode: 21500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-21500.pth
Episode: 21500 Reward: -92.442 Loss: 41.003
episode: 22000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-22000.pth
Episode: 22000 Reward: 47.511 Loss: 45.513
episode: 22500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-22500.pth
Episode: 22500 Reward: -30.147 Loss: 46.216
episode: 23000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-23000.pth
Episode: 23000 Reward: -37.134 Loss: 34.664
episode: 23500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-23500.pth
Episode: 23500 Reward: -145.773 Loss: 47.457
episode: 24000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-24000.pth
Episode: 24000 Reward: -6.591 Loss: 41.822
episode: 24500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-24500.pth
Episode: 24500 Reward: 7.736 Loss: 32.193
episode: 25000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-25000.pth
Episode: 25000 Reward: 102.371 Loss: 36.263
episode: 25500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-25500.pth
Episode: 25500 Reward: -336.409 Loss: 35.222
episode: 26000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-26000.pth
Episode: 26000 Reward: 109.927 Loss: 35.771
episode: 26500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-26500.pth
Episode: 26500 Reward: 142.893 Loss: 33.347
episode: 27000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-27000.pth
Episode: 27000 Reward: 38.093 Loss: 32.475
episode: 27500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-27500.pth
Episode: 27500 Reward: 89.855 Loss: 27.267
episode: 28000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-28000.pth
Episode: 28000 Reward: -33.037 Loss: 27.690
episode: 28500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-28500.pth
Episode: 28500 Reward: -174.580 Loss: 25.652
episode: 29000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-29000.pth
Episode: 29000 Reward: 116.802 Loss: 25.327
episode: 29500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-29500.pth
Episode: 29500 Reward: 115.671 Loss: 22.182
episode: 30000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-30000.pth
Episode: 30000 Reward: 127.577 Loss: 29.166
episode: 30500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-30500.pth
Episode: 30500 Reward: 123.658 Loss: 23.107
episode: 31000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-31000.pth
Episode: 31000 Reward: 66.904 Loss: 25.377
episode: 31500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-31500.pth
Episode: 31500 Reward: -133.769 Loss: 28.067
episode: 32000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-32000.pth
Episode: 32000 Reward: 83.826 Loss: 16.009
episode: 32500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-32500.pth
Episode: 32500 Reward: 168.080 Loss: 25.150
episode: 33000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-33000.pth
Episode: 33000 Reward: 150.052 Loss: 25.325
episode: 33500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-33500.pth
Episode: 33500 Reward: -155.265 Loss: 25.638
episode: 34000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-34000.pth
Episode: 34000 Reward: 112.700 Loss: 18.868
episode: 34500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-34500.pth
Episode: 34500 Reward: 86.241 Loss: 23.872
episode: 35000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-35000.pth
Episode: 35000 Reward: 99.198 Loss: 20.331
episode: 35500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-35500.pth
Episode: 35500 Reward: 51.255 Loss: 27.742
episode: 36000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-36000.pth
Episode: 36000 Reward: 93.267 Loss: 23.248
episode: 36500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-36500.pth
Episode: 36500 Reward: -215.456 Loss: 26.484
episode: 37000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-37000.pth
Episode: 37000 Reward: 90.587 Loss: 33.104
episode: 37500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-37500.pth
Episode: 37500 Reward: 167.602 Loss: 30.018
episode: 38000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-38000.pth
Episode: 38000 Reward: 108.467 Loss: 30.654
episode: 38500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-38500.pth
Episode: 38500 Reward: 83.648 Loss: 44.370
episode: 39000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-39000.pth
Episode: 39000 Reward: 109.175 Loss: 34.318
episode: 39500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-39500.pth
Episode: 39500 Reward: -32.896 Loss: 27.349
episode: 40000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-40000.pth
Episode: 40000 Reward: 165.412 Loss: 32.133
episode: 40500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-40500.pth
Episode: 40500 Reward: 126.394 Loss: 25.247
episode: 41000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-41000.pth
Episode: 41000 Reward: 83.781 Loss: 29.949
episode: 41500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-41500.pth
Episode: 41500 Reward: 143.784 Loss: 28.582
episode: 42000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-42000.pth
Episode: 42000 Reward: 108.313 Loss: 29.386
episode: 42500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-42500.pth
Episode: 42500 Reward: -43.490 Loss: 26.034
episode: 43000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-43000.pth
Episode: 43000 Reward: -4.925 Loss: 27.418
episode: 43500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-43500.pth
Episode: 43500 Reward: 79.686 Loss: 24.464
episode: 44000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-44000.pth
Episode: 44000 Reward: 124.919 Loss: 31.098
episode: 44500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-44500.pth
Episode: 44500 Reward: 217.322 Loss: 24.781
episode: 45000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-45000.pth
Episode: 45000 Reward: -90.439 Loss: 30.628
episode: 45500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-45500.pth
Episode: 45500 Reward: -24.783 Loss: 27.467
episode: 46000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-46000.pth
Episode: 46000 Reward: 126.166 Loss: 26.210
episode: 46500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-46500.pth
Episode: 46500 Reward: 111.366 Loss: 13.891
episode: 47000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-47000.pth
Episode: 47000 Reward: 149.147 Loss: 20.038
episode: 47500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-47500.pth
Episode: 47500 Reward: 155.078 Loss: 20.104
episode: 48000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-48000.pth
Episode: 48000 Reward: 184.618 Loss: 21.711
episode: 48500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-48500.pth
Episode: 48500 Reward: 204.514 Loss: 33.210
episode: 49000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-49000.pth
Episode: 49000 Reward: 17.173 Loss: 27.667
episode: 49500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-49500.pth
Episode: 49500 Reward: 1.081 Loss: 24.820
episode: 50000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-50000.pth
Episode: 50000 Reward: 122.073 Loss: 24.940
episode: 50500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-50500.pth
Episode: 50500 Reward: -24.545 Loss: 32.635
episode: 51000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-51000.pth
Episode: 51000 Reward: 120.354 Loss: 30.487
episode: 51500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-51500.pth
Episode: 51500 Reward: 72.717 Loss: 29.279
episode: 52000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-52000.pth
Episode: 52000 Reward: -20.050 Loss: 34.807
episode: 52500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-52500.pth
Episode: 52500 Reward: 138.476 Loss: 30.036
episode: 53000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-53000.pth
Episode: 53000 Reward: 167.763 Loss: 35.617
episode: 53500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-53500.pth
Episode: 53500 Reward: 152.854 Loss: 23.249
episode: 54000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-54000.pth
Episode: 54000 Reward: 148.858 Loss: 22.555
episode: 54500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-54500.pth
Episode: 54500 Reward: 153.007 Loss: 18.732
episode: 55000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-55000.pth
Episode: 55000 Reward: 169.165 Loss: 29.388
episode: 55500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-55500.pth
Episode: 55500 Reward: 13.185 Loss: 13.359
episode: 56000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-56000.pth
Episode: 56000 Reward: 196.095 Loss: 22.964
episode: 56500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-56500.pth
Episode: 56500 Reward: 16.935 Loss: 20.319
episode: 57000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-57000.pth
Episode: 57000 Reward: -68.087 Loss: 13.111
episode: 57500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-57500.pth
Episode: 57500 Reward: 216.703 Loss: 17.015
episode: 58000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-58000.pth
Episode: 58000 Reward: 147.348 Loss: 16.814
episode: 58500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-58500.pth
Episode: 58500 Reward: 143.174 Loss: 21.825
episode: 59000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-59000.pth
Episode: 59000 Reward: 168.444 Loss: 16.358
episode: 59500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-59500.pth
Episode: 59500 Reward: 149.931 Loss: 19.047
episode: 60000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-60000.pth
Episode: 60000 Reward: 211.665 Loss: 21.161
episode: 60500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-60500.pth
Episode: 60500 Reward: 147.112 Loss: 27.447
episode: 61000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-61000.pth
Episode: 61000 Reward: 95.610 Loss: 30.399
episode: 61500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-61500.pth
Episode: 61500 Reward: 158.464 Loss: 28.514
episode: 62000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-62000.pth
Episode: 62000 Reward: 152.012 Loss: 21.403
episode: 62500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-62500.pth
Episode: 62500 Reward: 132.730 Loss: 25.933
episode: 63000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-63000.pth
Episode: 63000 Reward: 182.923 Loss: 24.977
episode: 63500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-63500.pth
Episode: 63500 Reward: 165.323 Loss: 19.959
episode: 64000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-64000.pth
Episode: 64000 Reward: 208.604 Loss: 26.714
episode: 64500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-64500.pth
Episode: 64500 Reward: 211.524 Loss: 16.331
episode: 65000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-65000.pth
Episode: 65000 Reward: 87.749 Loss: 21.877
episode: 65500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-65500.pth
Episode: 65500 Reward: 211.374 Loss: 32.207
episode: 66000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-66000.pth
Episode: 66000 Reward: 213.928 Loss: 24.867
episode: 66500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-66500.pth
Episode: 66500 Reward: 70.564 Loss: 25.628
episode: 67000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-67000.pth
Episode: 67000 Reward: 207.675 Loss: 18.299
episode: 67500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-67500.pth
Episode: 67500 Reward: -26.720 Loss: 23.383
episode: 68000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-68000.pth
Episode: 68000 Reward: 135.929 Loss: 28.152
episode: 68500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-68500.pth
Episode: 68500 Reward: 147.200 Loss: 17.016
episode: 69000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-69000.pth
Episode: 69000 Reward: 147.276 Loss: 25.964
episode: 69500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-69500.pth
Episode: 69500 Reward: 164.220 Loss: 17.921
episode: 70000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-70000.pth
Episode: 70000 Reward: 162.199 Loss: 19.809
episode: 70500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-70500.pth
Episode: 70500 Reward: 146.235 Loss: 18.470
episode: 71000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-71000.pth
Episode: 71000 Reward: 121.863 Loss: 24.525
episode: 71500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-71500.pth
Episode: 71500 Reward: 200.824 Loss: 18.205
episode: 72000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-72000.pth
Episode: 72000 Reward: 167.240 Loss: 21.198
episode: 72500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-72500.pth
Episode: 72500 Reward: 174.508 Loss: 22.821
episode: 73000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-73000.pth
Episode: 73000 Reward: 211.632 Loss: 18.559
episode: 73500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-73500.pth
Episode: 73500 Reward: 168.327 Loss: 26.082
episode: 74000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-74000.pth
Episode: 74000 Reward: 67.912 Loss: 21.316
episode: 74500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-74500.pth
Episode: 74500 Reward: 22.653 Loss: 21.291
episode: 75000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-75000.pth
Episode: 75000 Reward: 138.216 Loss: 17.787
episode: 75500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-75500.pth
Episode: 75500 Reward: 189.869 Loss: 17.232
episode: 76000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-76000.pth
Episode: 76000 Reward: 198.727 Loss: 34.210
episode: 76500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-76500.pth
Episode: 76500 Reward: 13.674 Loss: 23.174
episode: 77000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-77000.pth
Episode: 77000 Reward: 164.467 Loss: 15.640
episode: 77500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-77500.pth
Episode: 77500 Reward: 131.018 Loss: 13.926
episode: 78000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-78000.pth
Episode: 78000 Reward: 220.081 Loss: 27.861
episode: 78500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-78500.pth
Episode: 78500 Reward: 97.945 Loss: 23.526
episode: 79000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-79000.pth
Episode: 79000 Reward: 124.434 Loss: 27.980
episode: 79500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-79500.pth
Episode: 79500 Reward: 230.434 Loss: 20.014
episode: 80000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-80000.pth
Episode: 80000 Reward: 189.407 Loss: 21.936
episode: 80500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-80500.pth
Episode: 80500 Reward: 179.235 Loss: 27.493
episode: 81000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-81000.pth
Episode: 81000 Reward: 115.676 Loss: 18.354
episode: 81500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-81500.pth
Episode: 81500 Reward: 138.379 Loss: 20.645
episode: 82000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-82000.pth
Episode: 82000 Reward: -16.838 Loss: 20.647
episode: 82500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-82500.pth
Episode: 82500 Reward: 236.985 Loss: 22.286
episode: 83000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-83000.pth
Episode: 83000 Reward: 75.881 Loss: 22.245
episode: 83500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-83500.pth
Episode: 83500 Reward: 180.360 Loss: 33.511
episode: 84000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-84000.pth
Episode: 84000 Reward: 166.343 Loss: 34.180
episode: 84500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-84500.pth
Episode: 84500 Reward: 168.585 Loss: 31.314
episode: 85000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-85000.pth
Episode: 85000 Reward: 237.738 Loss: 23.200
episode: 85500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-85500.pth
Episode: 85500 Reward: 209.070 Loss: 34.321
episode: 86000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-86000.pth
Episode: 86000 Reward: 197.056 Loss: 19.803
episode: 86500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-86500.pth
Episode: 86500 Reward: 38.605 Loss: 20.136
episode: 87000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-87000.pth
Episode: 87000 Reward: 25.704 Loss: 20.893
episode: 87500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-87500.pth
Episode: 87500 Reward: 194.508 Loss: 17.402
episode: 88000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-88000.pth
Episode: 88000 Reward: 237.545 Loss: 31.081
episode: 88500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-88500.pth
Episode: 88500 Reward: 193.777 Loss: 26.244
episode: 89000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-89000.pth
Episode: 89000 Reward: 192.464 Loss: 24.828
episode: 89500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-89500.pth
Episode: 89500 Reward: -8.539 Loss: 30.591
episode: 90000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-90000.pth
Episode: 90000 Reward: 45.929 Loss: 23.568
episode: 90500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-90500.pth
Episode: 90500 Reward: 135.444 Loss: 26.588
episode: 91000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-91000.pth
Episode: 91000 Reward: 172.676 Loss: 22.892
episode: 91500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-91500.pth
Episode: 91500 Reward: 237.297 Loss: 18.495
episode: 92000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-92000.pth
Episode: 92000 Reward: 186.131 Loss: 23.056
episode: 92500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-92500.pth
Episode: 92500 Reward: 160.844 Loss: 26.036
episode: 93000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-93000.pth
Episode: 93000 Reward: 99.310 Loss: 27.058
episode: 93500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-93500.pth
Episode: 93500 Reward: 187.345 Loss: 27.623
episode: 94000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-94000.pth
Episode: 94000 Reward: 110.787 Loss: 26.583
episode: 94500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-94500.pth
Episode: 94500 Reward: -14.520 Loss: 28.550
episode: 95000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-95000.pth
Episode: 95000 Reward: 186.925 Loss: 19.149
episode: 95500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-95500.pth
Episode: 95500 Reward: 145.179 Loss: 21.490
episode: 96000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-96000.pth
Episode: 96000 Reward: 175.507 Loss: 33.689
episode: 96500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-96500.pth
Episode: 96500 Reward: 240.021 Loss: 23.268
episode: 97000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-97000.pth
Episode: 97000 Reward: 193.955 Loss: 18.955
episode: 97500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-97500.pth
Episode: 97500 Reward: 162.939 Loss: 19.985
episode: 98000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-98000.pth
Episode: 98000 Reward: -102.898 Loss: 22.041
episode: 98500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-98500.pth
Episode: 98500 Reward: 27.264 Loss: 26.338
episode: 99000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-99000.pth
Episode: 99000 Reward: 182.261 Loss: 36.657
episode: 99500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-99500.pth
Episode: 99500 Reward: 67.148 Loss: 14.433
episode: 100000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_4s/model-100000.pth
Episode: 100000 Reward: 34.526 Loss: 18.149
