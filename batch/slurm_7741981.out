player initial finish
=> Restore ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-10500.pth
episode: 11000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-11000.pth
Episode: 11000 Reward: 279.967 Loss: 15.624
episode: 11500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-11500.pth
Episode: 11500 Reward: -256.767 Loss: 20.576
episode: 12000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-12000.pth
Episode: 12000 Reward: -55.004 Loss: 25.798
episode: 12500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-12500.pth
Episode: 12500 Reward: 208.874 Loss: 7.717
episode: 13000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-13000.pth
Episode: 13000 Reward: 156.895 Loss: 7.971
episode: 13500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-13500.pth
Episode: 13500 Reward: 304.972 Loss: 8.222
episode: 14000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-14000.pth
Episode: 14000 Reward: -20.395 Loss: 8.827
episode: 14500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-14500.pth
Episode: 14500 Reward: 191.040 Loss: 24.926
episode: 15000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-15000.pth
Episode: 15000 Reward: 411.881 Loss: 20.098
episode: 15500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-15500.pth
Episode: 15500 Reward: 328.983 Loss: 12.802
episode: 16000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-16000.pth
Episode: 16000 Reward: 385.707 Loss: 14.729
episode: 16500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-16500.pth
Episode: 16500 Reward: 360.871 Loss: 13.638
episode: 17000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-17000.pth
Episode: 17000 Reward: 244.501 Loss: 17.131
episode: 17500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-17500.pth
Episode: 17500 Reward: 374.047 Loss: 18.886
episode: 18000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-18000.pth
Episode: 18000 Reward: 55.668 Loss: 15.497
episode: 18500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-18500.pth
Episode: 18500 Reward: 381.619 Loss: 12.072
episode: 19000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-19000.pth
Episode: 19000 Reward: 311.396 Loss: 13.537
episode: 19500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-19500.pth
Episode: 19500 Reward: 387.960 Loss: 9.797
episode: 20000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-20000.pth
Episode: 20000 Reward: 419.059 Loss: 10.699
episode: 20500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-20500.pth
Episode: 20500 Reward: 371.604 Loss: 7.406
episode: 21000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-21000.pth
Episode: 21000 Reward: 281.828 Loss: 18.019
episode: 21500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-21500.pth
Episode: 21500 Reward: 334.696 Loss: 20.406
episode: 22000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-22000.pth
Episode: 22000 Reward: 378.130 Loss: 15.865
episode: 22500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-22500.pth
Episode: 22500 Reward: 405.281 Loss: 10.701
episode: 23000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-23000.pth
Episode: 23000 Reward: 360.174 Loss: 7.546
episode: 23500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-23500.pth
Episode: 23500 Reward: 102.470 Loss: 13.155
episode: 24000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-24000.pth
Episode: 24000 Reward: 263.518 Loss: 14.515
episode: 24500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-24500.pth
Episode: 24500 Reward: 351.305 Loss: 14.445
episode: 25000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-25000.pth
Episode: 25000 Reward: 364.817 Loss: 8.295
episode: 25500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-25500.pth
Episode: 25500 Reward: 436.161 Loss: 8.452
episode: 26000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-26000.pth
Episode: 26000 Reward: 384.009 Loss: 7.585
episode: 26500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-26500.pth
Episode: 26500 Reward: 438.517 Loss: 10.679
episode: 27000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-27000.pth
Episode: 27000 Reward: 223.436 Loss: 10.131
episode: 27500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-27500.pth
Episode: 27500 Reward: 414.831 Loss: 12.922
episode: 28000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-28000.pth
Episode: 28000 Reward: 427.063 Loss: 7.024
episode: 28500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-28500.pth
Episode: 28500 Reward: 75.218 Loss: 8.967
episode: 29000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-29000.pth
Episode: 29000 Reward: 426.787 Loss: 6.986
episode: 29500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-29500.pth
Episode: 29500 Reward: 248.187 Loss: 8.370
episode: 30000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-30000.pth
Episode: 30000 Reward: 430.900 Loss: 12.730
episode: 30500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-30500.pth
Episode: 30500 Reward: 397.253 Loss: 5.979
episode: 31000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-31000.pth
Episode: 31000 Reward: 53.465 Loss: 15.188
episode: 31500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-31500.pth
Episode: 31500 Reward: 181.117 Loss: 16.850
episode: 32000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-32000.pth
Episode: 32000 Reward: 314.585 Loss: 9.797
episode: 32500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-32500.pth
Episode: 32500 Reward: 242.233 Loss: 7.981
episode: 33000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-33000.pth
Episode: 33000 Reward: 427.307 Loss: 12.949
episode: 33500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-33500.pth
Episode: 33500 Reward: 437.347 Loss: 7.718
episode: 34000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-34000.pth
Episode: 34000 Reward: 435.860 Loss: 6.314
episode: 34500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-34500.pth
Episode: 34500 Reward: 375.212 Loss: 13.308
episode: 35000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-35000.pth
Episode: 35000 Reward: 423.535 Loss: 6.530
episode: 35500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-35500.pth
Episode: 35500 Reward: 434.479 Loss: 4.448
episode: 36000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-36000.pth
Episode: 36000 Reward: 131.445 Loss: 20.988
episode: 36500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-36500.pth
Episode: 36500 Reward: 421.855 Loss: 9.549
episode: 37000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-37000.pth
Episode: 37000 Reward: 353.200 Loss: 18.133
episode: 37500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-37500.pth
Episode: 37500 Reward: 143.663 Loss: 6.291
episode: 38000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-38000.pth
Episode: 38000 Reward: 30.032 Loss: 9.744
episode: 38500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-38500.pth
Episode: 38500 Reward: 439.718 Loss: 6.365
episode: 39000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-39000.pth
Episode: 39000 Reward: 227.809 Loss: 7.985
episode: 39500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-39500.pth
Episode: 39500 Reward: 416.966 Loss: 10.887
episode: 40000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-40000.pth
Episode: 40000 Reward: 434.521 Loss: 15.090
episode: 40500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-40500.pth
Episode: 40500 Reward: 442.983 Loss: 11.129
episode: 41000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-41000.pth
Episode: 41000 Reward: 441.595 Loss: 9.067
episode: 41500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-41500.pth
Episode: 41500 Reward: 437.288 Loss: 5.132
episode: 42000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-42000.pth
Episode: 42000 Reward: 395.458 Loss: 9.020
episode: 42500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-42500.pth
Episode: 42500 Reward: 193.328 Loss: 11.954
episode: 43000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-43000.pth
Episode: 43000 Reward: 402.687 Loss: 12.169
episode: 43500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-43500.pth
Episode: 43500 Reward: 440.654 Loss: 9.844
episode: 44000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-44000.pth
Episode: 44000 Reward: 445.016 Loss: 10.816
episode: 44500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-44500.pth
Episode: 44500 Reward: 428.479 Loss: 10.126
episode: 45000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-45000.pth
Episode: 45000 Reward: 309.991 Loss: 14.526
episode: 45500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-45500.pth
Episode: 45500 Reward: 276.376 Loss: 10.191
episode: 46000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-46000.pth
Episode: 46000 Reward: 417.637 Loss: 15.876
episode: 46500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-46500.pth
Episode: 46500 Reward: 444.164 Loss: 6.992
episode: 47000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-47000.pth
Episode: 47000 Reward: 424.709 Loss: 14.254
episode: 47500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-47500.pth
Episode: 47500 Reward: 82.333 Loss: 16.993
episode: 48000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-48000.pth
Episode: 48000 Reward: 182.444 Loss: 15.085
episode: 48500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-48500.pth
Episode: 48500 Reward: 425.723 Loss: 8.700
episode: 49000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-49000.pth
Episode: 49000 Reward: 124.370 Loss: 12.253
episode: 49500
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-49500.pth
Episode: 49500 Reward: 411.228 Loss: 13.189
episode: 50000
=> Save ./models/logs_m_2/q_2/t_2/l_0/latency_2s/model-50000.pth
Episode: 50000 Reward: 432.456 Loss: 12.842
